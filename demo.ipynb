{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_index</th>\n",
       "      <th>cons_conf_index</th>\n",
       "      <th>lending_rate3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>subscribe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>failure</td>\n",
       "      <td>1.4</td>\n",
       "      <td>90.81</td>\n",
       "      <td>-35.53</td>\n",
       "      <td>0.69</td>\n",
       "      <td>5219.74</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>412</td>\n",
       "      <td>2</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>96.33</td>\n",
       "      <td>-40.58</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4974.79</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>divorced</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1027</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>96.33</td>\n",
       "      <td>-44.74</td>\n",
       "      <td>1.50</td>\n",
       "      <td>5022.61</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>998</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>97.08</td>\n",
       "      <td>-35.55</td>\n",
       "      <td>5.11</td>\n",
       "      <td>5222.87</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>4</td>\n",
       "      <td>success</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>89.82</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>1.17</td>\n",
       "      <td>4884.70</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22496</th>\n",
       "      <td>33</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>925</td>\n",
       "      <td>3</td>\n",
       "      <td>failure</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.47</td>\n",
       "      <td>-43.30</td>\n",
       "      <td>3.36</td>\n",
       "      <td>5203.22</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22497</th>\n",
       "      <td>34</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>533</td>\n",
       "      <td>3</td>\n",
       "      <td>failure</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.64</td>\n",
       "      <td>-26.27</td>\n",
       "      <td>4.41</td>\n",
       "      <td>4914.80</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22498</th>\n",
       "      <td>25</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>792</td>\n",
       "      <td>5</td>\n",
       "      <td>success</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>90.43</td>\n",
       "      <td>-36.75</td>\n",
       "      <td>4.05</td>\n",
       "      <td>5114.30</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22499</th>\n",
       "      <td>57</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>989</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>89.38</td>\n",
       "      <td>-37.96</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5284.43</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22500</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>90.18</td>\n",
       "      <td>-46.20</td>\n",
       "      <td>1.45</td>\n",
       "      <td>5155.19</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22500 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age           job   marital            education  default  housing  \\\n",
       "id                                                                          \n",
       "1       51        admin.  divorced  professional.course       no      yes   \n",
       "2       50      services   married          high.school  unknown      yes   \n",
       "3       48   blue-collar  divorced             basic.9y       no       no   \n",
       "4       26  entrepreneur    single          high.school      yes      yes   \n",
       "5       45        admin.    single    university.degree       no       no   \n",
       "...    ...           ...       ...                  ...      ...      ...   \n",
       "22496   33        admin.   married          high.school       no       no   \n",
       "22497   34        admin.  divorced          high.school       no  unknown   \n",
       "22498   25        admin.   married  professional.course       no      yes   \n",
       "22499   57       retired   married          high.school       no      yes   \n",
       "22500   44   blue-collar   married             basic.9y  unknown      yes   \n",
       "\n",
       "          loan    contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "id                                           ...                              \n",
       "1          yes   cellular   aug         mon  ...         1    112         2   \n",
       "2           no   cellular   may         mon  ...         1    412         2   \n",
       "3           no   cellular   apr         wed  ...         0   1027         1   \n",
       "4          yes   cellular   aug         fri  ...        26    998         0   \n",
       "5           no   cellular   nov         tue  ...         1    240         4   \n",
       "...        ...        ...   ...         ...  ...       ...    ...       ...   \n",
       "22496       no   cellular   aug         fri  ...         3    925         3   \n",
       "22497  unknown   cellular   aug         fri  ...        14    533         3   \n",
       "22498       no   cellular   may         thu  ...         0    792         5   \n",
       "22499       no  telephone   may         tue  ...         5    989         0   \n",
       "22500       no   cellular   apr         fri  ...         0   1001         1   \n",
       "\n",
       "          poutcome emp_var_rate  cons_price_index  cons_conf_index  \\\n",
       "id                                                                   \n",
       "1          failure          1.4             90.81           -35.53   \n",
       "2      nonexistent         -1.8             96.33           -40.58   \n",
       "3          failure         -1.8             96.33           -44.74   \n",
       "4      nonexistent          1.4             97.08           -35.55   \n",
       "5          success         -3.4             89.82           -33.83   \n",
       "...            ...          ...               ...              ...   \n",
       "22496      failure         -2.9             92.47           -43.30   \n",
       "22497      failure          1.4             93.64           -26.27   \n",
       "22498      success         -1.8             90.43           -36.75   \n",
       "22499  nonexistent          1.1             89.38           -37.96   \n",
       "22500      failure         -1.8             90.18           -46.20   \n",
       "\n",
       "       lending_rate3m  nr_employed  subscribe  \n",
       "id                                             \n",
       "1                0.69      5219.74         no  \n",
       "2                4.05      4974.79        yes  \n",
       "3                1.50      5022.61         no  \n",
       "4                5.11      5222.87        yes  \n",
       "5                1.17      4884.70         no  \n",
       "...               ...          ...        ...  \n",
       "22496            3.36      5203.22        yes  \n",
       "22497            4.41      4914.80         no  \n",
       "22498            4.05      5114.30         no  \n",
       "22499            4.95      5284.43         no  \n",
       "22500            1.45      5155.19        yes  \n",
       "\n",
       "[22500 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', index_col='id')\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_index</th>\n",
       "      <th>cons_conf_index</th>\n",
       "      <th>lending_rate3m</th>\n",
       "      <th>nr_employed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22501</th>\n",
       "      <td>35</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>3295</td>\n",
       "      <td>1</td>\n",
       "      <td>476</td>\n",
       "      <td>0</td>\n",
       "      <td>success</td>\n",
       "      <td>1.4</td>\n",
       "      <td>95.37</td>\n",
       "      <td>-33.04</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5204.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22502</th>\n",
       "      <td>26</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>2872</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>success</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>91.75</td>\n",
       "      <td>-44.42</td>\n",
       "      <td>3.16</td>\n",
       "      <td>4924.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22503</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>268</td>\n",
       "      <td>3</td>\n",
       "      <td>968</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>89.67</td>\n",
       "      <td>-36.90</td>\n",
       "      <td>5.04</td>\n",
       "      <td>4947.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22504</th>\n",
       "      <td>36</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>thu</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>432</td>\n",
       "      <td>5</td>\n",
       "      <td>success</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>89.87</td>\n",
       "      <td>-41.66</td>\n",
       "      <td>3.27</td>\n",
       "      <td>5203.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22505</th>\n",
       "      <td>41</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>1670</td>\n",
       "      <td>1</td>\n",
       "      <td>944</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>1.1</td>\n",
       "      <td>97.64</td>\n",
       "      <td>-36.32</td>\n",
       "      <td>3.95</td>\n",
       "      <td>4992.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>49</td>\n",
       "      <td>admin.</td>\n",
       "      <td>unknown</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>3937</td>\n",
       "      <td>50</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>95.77</td>\n",
       "      <td>-40.50</td>\n",
       "      <td>3.86</td>\n",
       "      <td>5058.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>34</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>wed</td>\n",
       "      <td>584</td>\n",
       "      <td>8</td>\n",
       "      <td>440</td>\n",
       "      <td>3</td>\n",
       "      <td>failure</td>\n",
       "      <td>1.4</td>\n",
       "      <td>90.59</td>\n",
       "      <td>-47.29</td>\n",
       "      <td>1.77</td>\n",
       "      <td>5156.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>50</td>\n",
       "      <td>retired</td>\n",
       "      <td>single</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>mon</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>97.42</td>\n",
       "      <td>-39.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>5116.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>96.90</td>\n",
       "      <td>-37.68</td>\n",
       "      <td>5.18</td>\n",
       "      <td>5144.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>46</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>1785</td>\n",
       "      <td>2</td>\n",
       "      <td>387</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>1.4</td>\n",
       "      <td>97.49</td>\n",
       "      <td>-31.54</td>\n",
       "      <td>3.79</td>\n",
       "      <td>5082.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job   marital            education  default housing loan  \\\n",
       "id                                                                             \n",
       "22501   35   technician    single  professional.course       no     yes  yes   \n",
       "22502   26       admin.    single          high.school       no     yes   no   \n",
       "22503   44  blue-collar   married             basic.6y       no      no   no   \n",
       "22504   36  blue-collar   married             basic.9y       no     yes   no   \n",
       "22505   41  blue-collar   married             basic.4y       no     yes   no   \n",
       "...    ...          ...       ...                  ...      ...     ...  ...   \n",
       "29996   49       admin.   unknown    university.degree  unknown     yes  yes   \n",
       "29997   34  blue-collar   married             basic.4y       no      no   no   \n",
       "29998   50      retired    single             basic.4y       no     yes   no   \n",
       "29999   31   technician   married  professional.course       no      no   no   \n",
       "30000   46       admin.  divorced    university.degree       no     yes   no   \n",
       "\n",
       "         contact month day_of_week  duration  campaign  pdays  previous  \\\n",
       "id                                                                        \n",
       "22501   cellular   aug         mon      3295         1    476         0   \n",
       "22502   cellular   may         thu      2872         1    166         2   \n",
       "22503  telephone   may         mon       268         3    968         0   \n",
       "22504  telephone   nov         thu        30         1    432         5   \n",
       "22505  telephone   may         thu      1670         1    944         3   \n",
       "...          ...   ...         ...       ...       ...    ...       ...   \n",
       "29996  telephone   apr         fri      3937        50    302         1   \n",
       "29997   cellular   jul         wed       584         8    440         3   \n",
       "29998   cellular   jun         mon       102         3    997         0   \n",
       "29999   cellular   aug         thu       179         3   1028         0   \n",
       "30000   cellular   aug         mon      1785         2    387         3   \n",
       "\n",
       "          poutcome  emp_var_rate  cons_price_index  cons_conf_index  \\\n",
       "id                                                                    \n",
       "22501      success           1.4             95.37           -33.04   \n",
       "22502      success          -1.8             91.75           -44.42   \n",
       "22503  nonexistent           1.1             89.67           -36.90   \n",
       "22504      success          -0.1             89.87           -41.66   \n",
       "22505      success           1.1             97.64           -36.32   \n",
       "...            ...           ...               ...              ...   \n",
       "29996      failure          -1.8             95.77           -40.50   \n",
       "29997      failure           1.4             90.59           -47.29   \n",
       "29998  nonexistent          -2.9             97.42           -39.69   \n",
       "29999  nonexistent           1.4             96.90           -37.68   \n",
       "30000      success           1.4             97.49           -31.54   \n",
       "\n",
       "       lending_rate3m  nr_employed  \n",
       "id                                  \n",
       "22501            3.63      5204.54  \n",
       "22502            3.16      4924.78  \n",
       "22503            5.04      4947.02  \n",
       "22504            3.27      5203.33  \n",
       "22505            3.95      4992.02  \n",
       "...               ...          ...  \n",
       "29996            3.86      5058.64  \n",
       "29997            1.77      5156.70  \n",
       "29998            1.29      5116.80  \n",
       "29999            5.18      5144.45  \n",
       "30000            3.79      5082.25  \n",
       "\n",
       "[7500 rows x 20 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv', index_col='id')\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22500 entries, 1 to 22500\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   age               22500 non-null  int64  \n",
      " 1   job               22500 non-null  object \n",
      " 2   marital           22500 non-null  object \n",
      " 3   education         22500 non-null  object \n",
      " 4   default           22500 non-null  object \n",
      " 5   housing           22500 non-null  object \n",
      " 6   loan              22500 non-null  object \n",
      " 7   contact           22500 non-null  object \n",
      " 8   month             22500 non-null  object \n",
      " 9   day_of_week       22500 non-null  object \n",
      " 10  duration          22500 non-null  int64  \n",
      " 11  campaign          22500 non-null  int64  \n",
      " 12  pdays             22500 non-null  int64  \n",
      " 13  previous          22500 non-null  int64  \n",
      " 14  poutcome          22500 non-null  object \n",
      " 15  emp_var_rate      22500 non-null  float64\n",
      " 16  cons_price_index  22500 non-null  float64\n",
      " 17  cons_conf_index   22500 non-null  float64\n",
      " 18  lending_rate3m    22500 non-null  float64\n",
      " 19  nr_employed       22500 non-null  float64\n",
      " 20  subscribe         22500 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7500 entries, 22501 to 30000\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   age               7500 non-null   int64  \n",
      " 1   job               7500 non-null   object \n",
      " 2   marital           7500 non-null   object \n",
      " 3   education         7500 non-null   object \n",
      " 4   default           7500 non-null   object \n",
      " 5   housing           7500 non-null   object \n",
      " 6   loan              7500 non-null   object \n",
      " 7   contact           7500 non-null   object \n",
      " 8   month             7500 non-null   object \n",
      " 9   day_of_week       7500 non-null   object \n",
      " 10  duration          7500 non-null   int64  \n",
      " 11  campaign          7500 non-null   int64  \n",
      " 12  pdays             7500 non-null   int64  \n",
      " 13  previous          7500 non-null   int64  \n",
      " 14  poutcome          7500 non-null   object \n",
      " 15  emp_var_rate      7500 non-null   float64\n",
      " 16  cons_price_index  7500 non-null   float64\n",
      " 17  cons_conf_index   7500 non-null   float64\n",
      " 18  lending_rate3m    7500 non-null   float64\n",
      " 19  nr_employed       7500 non-null   float64\n",
      "dtypes: float64(5), int64(5), object(10)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['age',\n",
       "  'duration',\n",
       "  'campaign',\n",
       "  'pdays',\n",
       "  'previous',\n",
       "  'emp_var_rate',\n",
       "  'cons_price_index',\n",
       "  'cons_conf_index',\n",
       "  'lending_rate3m',\n",
       "  'nr_employed'],\n",
       " ['job',\n",
       "  'marital',\n",
       "  'education',\n",
       "  'default',\n",
       "  'housing',\n",
       "  'loan',\n",
       "  'contact',\n",
       "  'month',\n",
       "  'day_of_week',\n",
       "  'poutcome'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_feature = list(test.select_dtypes(exclude='object').columns)\n",
    "categorical_feature = list(test.select_dtypes(include='object').columns)\n",
    "\n",
    "numerical_feature, categorical_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job has 12 unique values\n",
      "marital has 4 unique values\n",
      "education has 8 unique values\n",
      "default has 3 unique values\n",
      "housing has 3 unique values\n",
      "loan has 3 unique values\n",
      "contact has 2 unique values\n",
      "month has 10 unique values\n",
      "day_of_week has 5 unique values\n",
      "poutcome has 3 unique values\n"
     ]
    }
   ],
   "source": [
    "for f in categorical_feature:\n",
    "    print(f'{f} has {train[f].nunique()} unique values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for f in categorical_feature:\n",
    "#     sns.countplot(x=f, data=train)\n",
    "#     plt.xticks(rotation=90)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'poutcome']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 类别特征中 month 和 day_of_week 表示上次和客户联系的月份和星期几，感觉价值不大\n",
    "categorical_feature.remove('month')\n",
    "categorical_feature.remove('day_of_week')\n",
    "\n",
    "categorical_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in numerical_feature:\n",
    "#     sns.boxplot(x=f, data=train)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "target = label_encoder.fit_transform(train['subscribe'])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[categorical_feature] = ordinal_encoder.fit_transform(train[categorical_feature])\n",
    "test[categorical_feature] =ordinal_encoder.fit_transform(test[categorical_feature])\n",
    "\n",
    "train.head(), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8764402  -1.05189393 -1.83968264 ...  0.74882794 -1.62091153\n",
      "   0.48356626]\n",
      " [ 0.79369853  0.88725694 -0.29666991 ... -0.12106489  0.46379014\n",
      "  -0.95168637]\n",
      " [ 0.6282152  -0.77487237 -1.83968264 ... -0.83764987 -1.11834952\n",
      "  -0.67149131]\n",
      " ...\n",
      " [-1.27484317 -1.05189393 -0.29666991 ...  0.53867561  0.46379014\n",
      "  -0.13424569]\n",
      " [ 1.37289021  0.33321384 -0.29666991 ...  0.33024584  1.02219238\n",
      "   0.86260889]\n",
      " [ 0.29724852 -0.77487237 -0.29666991 ... -1.08914364 -1.14937186\n",
      "   0.10534394]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train=scaler.fit_transform(train)\n",
    "test=scaler.fit_transform(test)\n",
    "\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 22500)\n",
      "10 12 -0.5254514665533215\n",
      "10 13 0.5412253715322823\n",
      "12 13 -0.558189933945216\n",
      "15 18 0.6237795165673179\n",
      "Done pearsonr\n"
     ]
    }
   ],
   "source": [
    "# 计算皮尔森相关系数\n",
    "p_train=train.T\n",
    "print(p_train.shape)\n",
    "from scipy.stats import pearsonr\n",
    "for i in range(0,len(p_train)):\n",
    "    for j in range(i+1,len(p_train)):\n",
    "        r=pearsonr(p_train[i],p_train[j])\n",
    "        if(abs(r[0])>0.5):\n",
    "            print(i,j,r[0])\n",
    "\n",
    "print(\"Done pearsonr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 14:17:18,553] A new study created in memory with name: no-name-a357aa2a-a400-4cb3-800b-c2f8586f6b68\n",
      "[I 2024-10-31 14:17:21,104] Trial 0 finished with value: 0.0 and parameters: {'num_leaves': 128, 'learning_rate': 0.0007778275630972396, 'n_estimators': 183, 'subsample': 0.5371166962524956, 'colsample_bytree': 0.22830062697860334}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-10-31 14:17:24,248] Trial 1 finished with value: 0.0 and parameters: {'num_leaves': 44, 'learning_rate': 0.00020862890012148528, 'n_estimators': 473, 'subsample': 0.6663987262582907, 'colsample_bytree': 0.3109520913043312}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-10-31 14:17:25,685] Trial 2 finished with value: 0.0 and parameters: {'num_leaves': 37, 'learning_rate': 0.0005841073167088887, 'n_estimators': 263, 'subsample': 0.577908856489042, 'colsample_bytree': 0.18501618276197246}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-10-31 14:17:32,443] Trial 3 finished with value: 0.0 and parameters: {'num_leaves': 180, 'learning_rate': 0.0001585310049570058, 'n_estimators': 405, 'subsample': 0.5050679439821285, 'colsample_bytree': 0.38882896274921563}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-10-31 14:17:38,793] Trial 4 finished with value: 0.36594287328743896 and parameters: {'num_leaves': 172, 'learning_rate': 0.0782545871254819, 'n_estimators': 337, 'subsample': 0.713551503401388, 'colsample_bytree': 0.28945965113994654}. Best is trial 4 with value: 0.36594287328743896.\n",
      "[I 2024-10-31 14:17:44,088] Trial 5 finished with value: 0.42183076644311085 and parameters: {'num_leaves': 91, 'learning_rate': 0.013572171077737848, 'n_estimators': 495, 'subsample': 0.5364868945230887, 'colsample_bytree': 0.6237320775382575}. Best is trial 5 with value: 0.42183076644311085.\n",
      "[I 2024-10-31 14:17:54,989] Trial 6 finished with value: 0.0 and parameters: {'num_leaves': 243, 'learning_rate': 1.1677121290713816e-05, 'n_estimators': 472, 'subsample': 0.5144743822682789, 'colsample_bytree': 0.6660390209752066}. Best is trial 5 with value: 0.42183076644311085.\n",
      "[I 2024-10-31 14:18:00,030] Trial 7 finished with value: 0.0 and parameters: {'num_leaves': 168, 'learning_rate': 1.1669171861938863e-05, 'n_estimators': 291, 'subsample': 0.7677831159585475, 'colsample_bytree': 0.30640311676736687}. Best is trial 5 with value: 0.42183076644311085.\n",
      "[I 2024-10-31 14:18:08,725] Trial 8 finished with value: 0.0 and parameters: {'num_leaves': 235, 'learning_rate': 2.2815162802850463e-05, 'n_estimators': 382, 'subsample': 0.992352099690265, 'colsample_bytree': 0.7117981414429284}. Best is trial 5 with value: 0.42183076644311085.\n",
      "[I 2024-10-31 14:18:13,239] Trial 9 finished with value: 0.0 and parameters: {'num_leaves': 74, 'learning_rate': 0.00020016376507826466, 'n_estimators': 497, 'subsample': 0.9522750213953641, 'colsample_bytree': 0.5046164146678059}. Best is trial 5 with value: 0.42183076644311085.\n",
      "[I 2024-10-31 14:18:15,087] Trial 10 finished with value: 0.4134184547754514 and parameters: {'num_leaves': 107, 'learning_rate': 0.022336148889278033, 'n_estimators': 129, 'subsample': 0.8355397581424867, 'colsample_bytree': 0.9985589636192919}. Best is trial 5 with value: 0.42183076644311085.\n",
      "[I 2024-10-31 14:18:16,717] Trial 11 finished with value: 0.3927883539673351 and parameters: {'num_leaves': 100, 'learning_rate': 0.021875614979040732, 'n_estimators': 112, 'subsample': 0.837967097303617, 'colsample_bytree': 0.9709864013406495}. Best is trial 5 with value: 0.42183076644311085.\n",
      "[I 2024-10-31 14:18:19,668] Trial 12 finished with value: 0.31511692577193656 and parameters: {'num_leaves': 99, 'learning_rate': 0.007240835293035692, 'n_estimators': 215, 'subsample': 0.8600660330119483, 'colsample_bytree': 0.9759594654771118}. Best is trial 5 with value: 0.42183076644311085.\n",
      "[I 2024-10-31 14:18:21,377] Trial 13 finished with value: 0.0 and parameters: {'num_leaves': 133, 'learning_rate': 0.004437268319628689, 'n_estimators': 101, 'subsample': 0.635269576043112, 'colsample_bytree': 0.7962940817719963}. Best is trial 5 with value: 0.42183076644311085.\n",
      "[I 2024-10-31 14:18:23,188] Trial 14 finished with value: 0.43006082189391587 and parameters: {'num_leaves': 75, 'learning_rate': 0.07909702383693648, 'n_estimators': 170, 'subsample': 0.8103982959461898, 'colsample_bytree': 0.8297433418437385}. Best is trial 14 with value: 0.43006082189391587.\n",
      "[I 2024-10-31 14:18:25,077] Trial 15 finished with value: 0.4289975166591269 and parameters: {'num_leaves': 62, 'learning_rate': 0.09949081918151013, 'n_estimators': 215, 'subsample': 0.7491323114621544, 'colsample_bytree': 0.830457182688931}. Best is trial 14 with value: 0.43006082189391587.\n",
      "[I 2024-10-31 14:18:25,846] Trial 16 finished with value: 0.43289014730299724 and parameters: {'num_leaves': 18, 'learning_rate': 0.09883345109125945, 'n_estimators': 184, 'subsample': 0.7663974271073934, 'colsample_bytree': 0.819839483707065}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:26,733] Trial 17 finished with value: 0.0 and parameters: {'num_leaves': 21, 'learning_rate': 0.0032990081249790787, 'n_estimators': 165, 'subsample': 0.889662311079475, 'colsample_bytree': 0.8419930530146813}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:27,648] Trial 18 finished with value: 0.406906799380252 and parameters: {'num_leaves': 15, 'learning_rate': 0.040776459388950366, 'n_estimators': 244, 'subsample': 0.7557297884144596, 'colsample_bytree': 0.48994683956669277}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:29,011] Trial 19 finished with value: 0.0 and parameters: {'num_leaves': 52, 'learning_rate': 0.0019041338938242155, 'n_estimators': 159, 'subsample': 0.8068703018227191, 'colsample_bytree': 0.751815637121219}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:32,235] Trial 20 finished with value: 0.42972100895282994 and parameters: {'num_leaves': 73, 'learning_rate': 0.0470941290376979, 'n_estimators': 329, 'subsample': 0.9075856763623148, 'colsample_bytree': 0.909431278889541}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:35,488] Trial 21 finished with value: 0.4327693084596442 and parameters: {'num_leaves': 74, 'learning_rate': 0.04547343399569628, 'n_estimators': 330, 'subsample': 0.8861146731211573, 'colsample_bytree': 0.8878515253782028}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:37,161] Trial 22 finished with value: 0.364183154321283 and parameters: {'num_leaves': 27, 'learning_rate': 0.011467267970704709, 'n_estimators': 293, 'subsample': 0.921298810556589, 'colsample_bytree': 0.8906461808530889}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:40,414] Trial 23 finished with value: 0.4173977996893211 and parameters: {'num_leaves': 70, 'learning_rate': 0.043367996840823105, 'n_estimators': 379, 'subsample': 0.795901719140121, 'colsample_bytree': 0.5982541249460974}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:43,450] Trial 24 finished with value: 0.41725927007436414 and parameters: {'num_leaves': 122, 'learning_rate': 0.0867482079097306, 'n_estimators': 205, 'subsample': 0.6960936852963392, 'colsample_bytree': 0.7590884486155537}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:45,435] Trial 25 finished with value: 0.42903797131594984 and parameters: {'num_leaves': 45, 'learning_rate': 0.02472435226850278, 'n_estimators': 262, 'subsample': 0.8631971414948639, 'colsample_bytree': 0.8819422867380227}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:47,968] Trial 26 finished with value: 0.4194971639278777 and parameters: {'num_leaves': 149, 'learning_rate': 0.051272806235534665, 'n_estimators': 147, 'subsample': 0.7989716873039838, 'colsample_bytree': 0.6884753297889619}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:51,975] Trial 27 finished with value: 0.43024634054141975 and parameters: {'num_leaves': 84, 'learning_rate': 0.011883690497469717, 'n_estimators': 335, 'subsample': 0.7248955123876482, 'colsample_bytree': 0.9035406156308078}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:18:56,009] Trial 28 finished with value: 0.4133809216135025 and parameters: {'num_leaves': 84, 'learning_rate': 0.009408949839735852, 'n_estimators': 335, 'subsample': 0.603323397343961, 'colsample_bytree': 0.9180647409701188}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:19:02,122] Trial 29 finished with value: 0.0 and parameters: {'num_leaves': 112, 'learning_rate': 0.0010961757162968899, 'n_estimators': 424, 'subsample': 0.7017317576553211, 'colsample_bytree': 0.938968784028706}. Best is trial 16 with value: 0.43289014730299724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 14:19:08,560] Trial 30 finished with value: 0.04016779114744287 and parameters: {'num_leaves': 213, 'learning_rate': 0.0053888793387301265, 'n_estimators': 356, 'subsample': 0.7318456554189703, 'colsample_bytree': 0.12680423712305106}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:19:10,686] Trial 31 finished with value: 0.4314747140305806 and parameters: {'num_leaves': 56, 'learning_rate': 0.02387619892710509, 'n_estimators': 235, 'subsample': 0.6696887910293833, 'colsample_bytree': 0.8301893198006483}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:19:13,243] Trial 32 finished with value: 0.42543297747837505 and parameters: {'num_leaves': 52, 'learning_rate': 0.020615070955034752, 'n_estimators': 308, 'subsample': 0.6659233977065308, 'colsample_bytree': 0.760883606421336}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:19:14,758] Trial 33 finished with value: 0.41762457854954455 and parameters: {'num_leaves': 36, 'learning_rate': 0.037086762152166323, 'n_estimators': 244, 'subsample': 0.6651247750031564, 'colsample_bytree': 0.8531637317018604}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:19:16,570] Trial 34 finished with value: 0.3789195843895047 and parameters: {'num_leaves': 55, 'learning_rate': 0.015281216980956313, 'n_estimators': 198, 'subsample': 0.6974035039726572, 'colsample_bytree': 0.7931381905779364}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:19:18,169] Trial 35 finished with value: 0.0 and parameters: {'num_leaves': 32, 'learning_rate': 0.0005729274985691543, 'n_estimators': 271, 'subsample': 0.6353707382345569, 'colsample_bytree': 0.7133731177871733}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:19:20,591] Trial 36 finished with value: 0.0 and parameters: {'num_leaves': 90, 'learning_rate': 0.002139480213887982, 'n_estimators': 234, 'subsample': 0.5642852438671763, 'colsample_bytree': 0.4266903373750988}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:19:22,580] Trial 37 finished with value: 0.41437157327648066 and parameters: {'num_leaves': 43, 'learning_rate': 0.03040045463274527, 'n_estimators': 311, 'subsample': 0.6301231330311413, 'colsample_bytree': 0.6195500241474485}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:19:27,282] Trial 38 finished with value: 0.42712951005055144 and parameters: {'num_leaves': 148, 'learning_rate': 0.0635735340093762, 'n_estimators': 275, 'subsample': 0.7750415295615438, 'colsample_bytree': 0.9499284793215373}. Best is trial 16 with value: 0.43289014730299724.\n",
      "[I 2024-10-31 14:19:31,093] Trial 39 finished with value: 0.43438917500786534 and parameters: {'num_leaves': 62, 'learning_rate': 0.013515787681819184, 'n_estimators': 423, 'subsample': 0.7271665212451176, 'colsample_bytree': 0.8869938916342206}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:19:34,511] Trial 40 finished with value: 0.0 and parameters: {'num_leaves': 59, 'learning_rate': 6.253154054702526e-05, 'n_estimators': 433, 'subsample': 0.9703115902071237, 'colsample_bytree': 0.5695781500937945}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:19:38,973] Trial 41 finished with value: 0.4321427091565663 and parameters: {'num_leaves': 86, 'learning_rate': 0.014158754960888937, 'n_estimators': 362, 'subsample': 0.7148663917134778, 'colsample_bytree': 0.8778715278316401}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:19:43,987] Trial 42 finished with value: 0.3903997085900599 and parameters: {'num_leaves': 65, 'learning_rate': 0.0068447304103422205, 'n_estimators': 450, 'subsample': 0.6801279102334076, 'colsample_bytree': 0.7991091590886271}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:19:46,769] Trial 43 finished with value: 0.42165687702807303 and parameters: {'num_leaves': 37, 'learning_rate': 0.01869719039899741, 'n_estimators': 390, 'subsample': 0.7223772554612524, 'colsample_bytree': 0.8574441233362012}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:19:48,871] Trial 44 finished with value: 0.0 and parameters: {'num_leaves': 25, 'learning_rate': 0.000371408300493891, 'n_estimators': 362, 'subsample': 0.7433579794734914, 'colsample_bytree': 0.9411169890142127}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:19:55,997] Trial 45 finished with value: 0.4324139339840924 and parameters: {'num_leaves': 116, 'learning_rate': 0.06178182789440185, 'n_estimators': 403, 'subsample': 0.6075856321270747, 'colsample_bytree': 0.9973570637048856}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:20:03,752] Trial 46 finished with value: 0.4214650396284685 and parameters: {'num_leaves': 125, 'learning_rate': 0.0663731834804756, 'n_estimators': 475, 'subsample': 0.5501876107412506, 'colsample_bytree': 0.9920928018384214}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:20:08,909] Trial 47 finished with value: 0.4130917046157835 and parameters: {'num_leaves': 107, 'learning_rate': 0.031198820842027786, 'n_estimators': 415, 'subsample': 0.6000546895802213, 'colsample_bytree': 0.6606858392844617}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:20:13,798] Trial 48 finished with value: 0.4203445348038934 and parameters: {'num_leaves': 96, 'learning_rate': 0.06447943742197183, 'n_estimators': 402, 'subsample': 0.7746290062350426, 'colsample_bytree': 0.8773949416905655}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:20:20,274] Trial 49 finished with value: 0.4090034684516187 and parameters: {'num_leaves': 150, 'learning_rate': 0.09602225234106293, 'n_estimators': 362, 'subsample': 0.5225956848022875, 'colsample_bytree': 0.9670810848491427}. Best is trial 39 with value: 0.43438917500786534.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 14:20:25,820] Trial 50 finished with value: 0.32953497516640096 and parameters: {'num_leaves': 116, 'learning_rate': 0.014076254588929825, 'n_estimators': 444, 'subsample': 0.8332136807395942, 'colsample_bytree': 0.22025556187633766}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:20:30,092] Trial 51 finished with value: 0.42630507285989816 and parameters: {'num_leaves': 82, 'learning_rate': 0.0302697502963119, 'n_estimators': 397, 'subsample': 0.645399152838936, 'colsample_bytree': 0.814345554082816}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:20:35,230] Trial 52 finished with value: 0.20920553496980202 and parameters: {'num_leaves': 102, 'learning_rate': 0.0031268140424652547, 'n_estimators': 375, 'subsample': 0.6005954351198793, 'colsample_bytree': 0.9193084613860472}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:20:38,041] Trial 53 finished with value: 0.3788907373607597 and parameters: {'num_leaves': 46, 'learning_rate': 0.00945830654474961, 'n_estimators': 348, 'subsample': 0.6724905811433392, 'colsample_bytree': 0.7304955688178055}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:20:42,551] Trial 54 finished with value: 0.42615211612473347 and parameters: {'num_leaves': 76, 'learning_rate': 0.05139668667805064, 'n_estimators': 463, 'subsample': 0.6147260657062823, 'colsample_bytree': 0.8587614188831093}. Best is trial 39 with value: 0.43438917500786534.\n",
      "[I 2024-10-31 14:20:45,807] Trial 55 finished with value: 0.4417271213856594 and parameters: {'num_leaves': 140, 'learning_rate': 0.019439145511754085, 'n_estimators': 185, 'subsample': 0.7101336400997881, 'colsample_bytree': 0.9972805628963732}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:20:48,976] Trial 56 finished with value: 0.4255501772469524 and parameters: {'num_leaves': 135, 'learning_rate': 0.016393959066053933, 'n_estimators': 182, 'subsample': 0.5797814803224729, 'colsample_bytree': 0.9991512923546836}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:20:56,812] Trial 57 finished with value: 0.4210257838611497 and parameters: {'num_leaves': 163, 'learning_rate': 0.039362360686519965, 'n_estimators': 415, 'subsample': 0.7572176447244641, 'colsample_bytree': 0.9674120574217902}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:20:59,139] Trial 58 finished with value: 0.2060687826531578 and parameters: {'num_leaves': 142, 'learning_rate': 0.008324478176872997, 'n_estimators': 129, 'subsample': 0.8576781029051871, 'colsample_bytree': 0.936543284610754}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:21:04,023] Trial 59 finished with value: 0.3196288296248739 and parameters: {'num_leaves': 118, 'learning_rate': 0.005163274403131439, 'n_estimators': 321, 'subsample': 0.9342104238630298, 'colsample_bytree': 0.8850991819356997}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:21:08,258] Trial 60 finished with value: 0.4240767511737242 and parameters: {'num_leaves': 91, 'learning_rate': 0.06664965828233345, 'n_estimators': 383, 'subsample': 0.7099046893264155, 'colsample_bytree': 0.7794882908205961}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:21:10,125] Trial 61 finished with value: 0.42443213238593086 and parameters: {'num_leaves': 64, 'learning_rate': 0.02401244880940815, 'n_estimators': 187, 'subsample': 0.6862312312588483, 'colsample_bytree': 0.8308874966994119}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:21:10,936] Trial 62 finished with value: 0.4351906200150936 and parameters: {'num_leaves': 15, 'learning_rate': 0.09771401701108336, 'n_estimators': 226, 'subsample': 0.7383335083519859, 'colsample_bytree': 0.9111465094063864}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:21:11,583] Trial 63 finished with value: 0.42466728029955336 and parameters: {'num_leaves': 17, 'learning_rate': 0.09560308731586765, 'n_estimators': 150, 'subsample': 0.782793752668899, 'colsample_bytree': 0.9159479804871336}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:21:15,820] Trial 64 finished with value: 0.42122048392955647 and parameters: {'num_leaves': 162, 'learning_rate': 0.051289383041468635, 'n_estimators': 215, 'subsample': 0.7424837815234906, 'colsample_bytree': 0.9676151593755467}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:21:16,838] Trial 65 finished with value: 0.4160868067123672 and parameters: {'num_leaves': 27, 'learning_rate': 0.03665817424442989, 'n_estimators': 175, 'subsample': 0.8851326269203756, 'colsample_bytree': 0.8839946926991404}. Best is trial 55 with value: 0.4417271213856594.\n",
      "[I 2024-10-31 14:21:18,953] Trial 66 finished with value: 0.4424385009162391 and parameters: {'num_leaves': 129, 'learning_rate': 0.059698992386839254, 'n_estimators': 127, 'subsample': 0.7319576332783391, 'colsample_bytree': 0.9991527819551977}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:20,928] Trial 67 finished with value: 0.430272522601168 and parameters: {'num_leaves': 129, 'learning_rate': 0.07446075899053672, 'n_estimators': 119, 'subsample': 0.8207824568496429, 'colsample_bytree': 0.9931379442138223}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:23,555] Trial 68 finished with value: 0.43624333899767753 and parameters: {'num_leaves': 142, 'learning_rate': 0.05485307675216263, 'n_estimators': 142, 'subsample': 0.6514076205269843, 'colsample_bytree': 0.9482090360554524}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:26,822] Trial 69 finished with value: 0.4365771551351137 and parameters: {'num_leaves': 192, 'learning_rate': 0.04388820683614907, 'n_estimators': 136, 'subsample': 0.6564959153277612, 'colsample_bytree': 0.9252800113155176}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:29,185] Trial 70 finished with value: 0.41685093411413054 and parameters: {'num_leaves': 195, 'learning_rate': 0.028764613649746723, 'n_estimators': 101, 'subsample': 0.6571325198978669, 'colsample_bytree': 0.9457271033538669}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:32,190] Trial 71 finished with value: 0.4391400394631241 and parameters: {'num_leaves': 184, 'learning_rate': 0.045304142973695866, 'n_estimators': 140, 'subsample': 0.7634550286168273, 'colsample_bytree': 0.9083375404234723}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:35,064] Trial 72 finished with value: 0.37678143342205456 and parameters: {'num_leaves': 194, 'learning_rate': 0.0759578836522491, 'n_estimators': 140, 'subsample': 0.734542195987137, 'colsample_bytree': 0.3488235011361974}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:38,449] Trial 73 finished with value: 0.431098235879311 and parameters: {'num_leaves': 181, 'learning_rate': 0.05112033190511628, 'n_estimators': 164, 'subsample': 0.759874547948648, 'colsample_bytree': 0.9152237864619349}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:40,933] Trial 74 finished with value: 0.43759974300766125 and parameters: {'num_leaves': 178, 'learning_rate': 0.09903692545959387, 'n_estimators': 117, 'subsample': 0.7889924707466649, 'colsample_bytree': 0.9603134308649484}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:43,412] Trial 75 finished with value: 0.4325468745677801 and parameters: {'num_leaves': 179, 'learning_rate': 0.03811105444344011, 'n_estimators': 115, 'subsample': 0.796989845916135, 'colsample_bytree': 0.9498060348902718}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:46,825] Trial 76 finished with value: 0.42680916616766507 and parameters: {'num_leaves': 226, 'learning_rate': 0.09919699509911252, 'n_estimators': 133, 'subsample': 0.7886998717412393, 'colsample_bytree': 0.9688996142054088}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:49,671] Trial 77 finished with value: 0.43143610546726413 and parameters: {'num_leaves': 204, 'learning_rate': 0.05671074944816448, 'n_estimators': 122, 'subsample': 0.6904292736647291, 'colsample_bytree': 0.9071321537274257}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:52,605] Trial 78 finished with value: 0.0 and parameters: {'num_leaves': 178, 'learning_rate': 0.00010004749571268105, 'n_estimators': 154, 'subsample': 0.7123497663992044, 'colsample_bytree': 0.9352263189601985}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:55,708] Trial 79 finished with value: 0.41023041260962917 and parameters: {'num_leaves': 188, 'learning_rate': 0.020372303267620292, 'n_estimators': 141, 'subsample': 0.6528680284384605, 'colsample_bytree': 0.8635691177947586}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:21:57,663] Trial 80 finished with value: 0.0 and parameters: {'num_leaves': 167, 'learning_rate': 1.8137574242191368e-05, 'n_estimators': 104, 'subsample': 0.7357222623198234, 'colsample_bytree': 0.9696075121039376}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:22:02,438] Trial 81 finished with value: 0.42792907335444924 and parameters: {'num_leaves': 215, 'learning_rate': 0.07453092408341228, 'n_estimators': 193, 'subsample': 0.7565486158836155, 'colsample_bytree': 0.9264161983540014}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:22:05,542] Trial 82 finished with value: 0.436723645418758 and parameters: {'num_leaves': 158, 'learning_rate': 0.04427601663917029, 'n_estimators': 172, 'subsample': 0.7094914963905524, 'colsample_bytree': 0.9001474553199051}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:22:08,662] Trial 83 finished with value: 0.4290306400124126 and parameters: {'num_leaves': 159, 'learning_rate': 0.03287915773961811, 'n_estimators': 169, 'subsample': 0.7001676903142746, 'colsample_bytree': 0.8958604399682869}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:22:11,219] Trial 84 finished with value: 0.4346030033037967 and parameters: {'num_leaves': 156, 'learning_rate': 0.0442148694744159, 'n_estimators': 136, 'subsample': 0.7221904239681595, 'colsample_bytree': 0.9537088076650011}. Best is trial 66 with value: 0.4424385009162391.\n",
      "[I 2024-10-31 14:22:13,794] Trial 85 finished with value: 0.4467462624452061 and parameters: {'num_leaves': 156, 'learning_rate': 0.041965253111443356, 'n_estimators': 138, 'subsample': 0.8143873493140596, 'colsample_bytree': 0.9565412510447763}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:16,824] Trial 86 finished with value: 0.428562253079477 and parameters: {'num_leaves': 170, 'learning_rate': 0.0806671785259415, 'n_estimators': 155, 'subsample': 0.8242286887331384, 'colsample_bytree': 0.9804022864761379}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:18,842] Trial 87 finished with value: 0.3965403984318207 and parameters: {'num_leaves': 145, 'learning_rate': 0.023830276806338434, 'n_estimators': 111, 'subsample': 0.7691228276288762, 'colsample_bytree': 0.8503859686365927}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:21,063] Trial 88 finished with value: 0.3955721255499969 and parameters: {'num_leaves': 141, 'learning_rate': 0.04266772087849889, 'n_estimators': 145, 'subsample': 0.7845502075906924, 'colsample_bytree': 0.4603436941034696}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:24,190] Trial 89 finished with value: 0.43831859075827034 and parameters: {'num_leaves': 154, 'learning_rate': 0.05745681535854448, 'n_estimators': 176, 'subsample': 0.7460826765598506, 'colsample_bytree': 0.9781310288242105}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:26,361] Trial 90 finished with value: 0.43157760321072847 and parameters: {'num_leaves': 134, 'learning_rate': 0.02723369633342246, 'n_estimators': 126, 'subsample': 0.8493608438168625, 'colsample_bytree': 0.9783177186501802}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:30,112] Trial 91 finished with value: 0.4306560255881326 and parameters: {'num_leaves': 154, 'learning_rate': 0.05063231782388035, 'n_estimators': 206, 'subsample': 0.8172049526799402, 'colsample_bytree': 0.9540976592721262}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:33,681] Trial 92 finished with value: 0.4306709584692456 and parameters: {'num_leaves': 174, 'learning_rate': 0.05861071103608442, 'n_estimators': 177, 'subsample': 0.6822535042055482, 'colsample_bytree': 0.9277029558612853}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:37,298] Trial 93 finished with value: 0.42482696974763423 and parameters: {'num_leaves': 192, 'learning_rate': 0.08158059455598148, 'n_estimators': 163, 'subsample': 0.7395064641421365, 'colsample_bytree': 0.904560371438578}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:42,133] Trial 94 finished with value: 0.425120284920909 and parameters: {'num_leaves': 187, 'learning_rate': 0.035673048448015915, 'n_estimators': 222, 'subsample': 0.7068511508536552, 'colsample_bytree': 0.9843569434563902}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:44,811] Trial 95 finished with value: 0.4360013020693649 and parameters: {'num_leaves': 139, 'learning_rate': 0.06246159361526632, 'n_estimators': 158, 'subsample': 0.7513108240203635, 'colsample_bytree': 0.9993395895397906}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:47,494] Trial 96 finished with value: 0.42134615807626136 and parameters: {'num_leaves': 139, 'learning_rate': 0.018984333086309563, 'n_estimators': 158, 'subsample': 0.8064322793815317, 'colsample_bytree': 0.9979113911208173}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:49,560] Trial 97 finished with value: 0.4364394039252038 and parameters: {'num_leaves': 152, 'learning_rate': 0.04463610326146688, 'n_estimators': 110, 'subsample': 0.7728077012178093, 'colsample_bytree': 0.9542623784309224}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:51,719] Trial 98 finished with value: 0.438808230540629 and parameters: {'num_leaves': 152, 'learning_rate': 0.04576761752710078, 'n_estimators': 110, 'subsample': 0.7730743890110287, 'colsample_bytree': 0.9535924432601199}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:53,779] Trial 99 finished with value: 0.4318031306679332 and parameters: {'num_leaves': 152, 'learning_rate': 0.04266432216447223, 'n_estimators': 109, 'subsample': 0.7662319618813571, 'colsample_bytree': 0.8716923812097523}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:55,984] Trial 100 finished with value: 0.35485361228356815 and parameters: {'num_leaves': 165, 'learning_rate': 0.026228355791332588, 'n_estimators': 125, 'subsample': 0.7847372987347071, 'colsample_bytree': 0.528346789865351}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:22:58,238] Trial 101 finished with value: 0.4411613622383964 and parameters: {'num_leaves': 129, 'learning_rate': 0.03179632186710821, 'n_estimators': 135, 'subsample': 0.8105439370119031, 'colsample_bytree': 0.955742301945492}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:00,202] Trial 102 finished with value: 0.37855241381127697 and parameters: {'num_leaves': 128, 'learning_rate': 0.01811747433615965, 'n_estimators': 118, 'subsample': 0.8067141623632065, 'colsample_bytree': 0.930311243102953}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:02,632] Trial 103 finished with value: 0.435718383233288 and parameters: {'num_leaves': 147, 'learning_rate': 0.03667638404376172, 'n_estimators': 133, 'subsample': 0.7723409516502893, 'colsample_bytree': 0.9604912001337695}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:04,926] Trial 104 finished with value: 0.4406430411916379 and parameters: {'num_leaves': 172, 'learning_rate': 0.03230446636263022, 'n_estimators': 110, 'subsample': 0.8329309118339602, 'colsample_bytree': 0.9788538589079381}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:08,442] Trial 105 finished with value: 0.4363455752559407 and parameters: {'num_leaves': 203, 'learning_rate': 0.03244860677987034, 'n_estimators': 148, 'subsample': 0.8440588239209277, 'colsample_bytree': 0.9788821004764129}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:11,088] Trial 106 finished with value: 0.2922862512520182 and parameters: {'num_leaves': 173, 'learning_rate': 0.0105679028395481, 'n_estimators': 131, 'subsample': 0.8309031387143677, 'colsample_bytree': 0.9258211791689248}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:13,296] Trial 107 finished with value: 0.3910454102602496 and parameters: {'num_leaves': 183, 'learning_rate': 0.023246557711130024, 'n_estimators': 102, 'subsample': 0.8709767172205733, 'colsample_bytree': 0.8989397108179068}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:16,398] Trial 108 finished with value: 0.4317885275719999 and parameters: {'num_leaves': 158, 'learning_rate': 0.07067497483146541, 'n_estimators': 171, 'subsample': 0.7976135031563458, 'colsample_bytree': 0.9770085733312625}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:18,373] Trial 109 finished with value: 0.42377529322694396 and parameters: {'num_leaves': 122, 'learning_rate': 0.029025948063592384, 'n_estimators': 121, 'subsample': 0.7238412438885056, 'colsample_bytree': 0.9401117963474358}. Best is trial 85 with value: 0.4467462624452061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 14:23:22,039] Trial 110 finished with value: 0.22675738802682516 and parameters: {'num_leaves': 200, 'learning_rate': 0.016280381220229727, 'n_estimators': 188, 'subsample': 0.8149412127755943, 'colsample_bytree': 0.2694151976564684}. Best is trial 85 with value: 0.4467462624452061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 14:23:24,279] Trial 111 finished with value: 0.4399512898256036 and parameters: {'num_leaves': 161, 'learning_rate': 0.04579973301557239, 'n_estimators': 111, 'subsample': 0.7632185152428784, 'colsample_bytree': 0.961145798110196}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:26,741] Trial 112 finished with value: 0.4372933789532093 and parameters: {'num_leaves': 175, 'learning_rate': 0.04892442764388521, 'n_estimators': 116, 'subsample': 0.7484813476666795, 'colsample_bytree': 0.9612797517415232}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:28,989] Trial 113 finished with value: 0.43856951356595947 and parameters: {'num_leaves': 161, 'learning_rate': 0.048872941005382545, 'n_estimators': 116, 'subsample': 0.7513101188283353, 'colsample_bytree': 0.9629585228524258}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:31,237] Trial 114 finished with value: 0.43320469209461454 and parameters: {'num_leaves': 168, 'learning_rate': 0.05986558333007201, 'n_estimators': 113, 'subsample': 0.7488458731910529, 'colsample_bytree': 0.9617746070312215}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:33,206] Trial 115 finished with value: 0.0 and parameters: {'num_leaves': 176, 'learning_rate': 0.0010410539909891528, 'n_estimators': 100, 'subsample': 0.7928552617864982, 'colsample_bytree': 0.9801695834060462}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:35,525] Trial 116 finished with value: 0.0 and parameters: {'num_leaves': 163, 'learning_rate': 0.0013650522648538004, 'n_estimators': 126, 'subsample': 0.7625576509706109, 'colsample_bytree': 0.9988611150372276}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:37,902] Trial 117 finished with value: 0.42922317973461305 and parameters: {'num_leaves': 184, 'learning_rate': 0.0840946752929439, 'n_estimators': 108, 'subsample': 0.780252711500791, 'colsample_bytree': 0.9423375666170601}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:39,883] Trial 118 finished with value: 0.4339774498581691 and parameters: {'num_leaves': 131, 'learning_rate': 0.03431590777136165, 'n_estimators': 117, 'subsample': 0.7487862140968807, 'colsample_bytree': 0.962372926435728}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:43,801] Trial 119 finished with value: 0.4313271016069855 and parameters: {'num_leaves': 251, 'learning_rate': 0.05074896713822863, 'n_estimators': 140, 'subsample': 0.8058664613327808, 'colsample_bytree': 0.9800778543024283}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:46,124] Trial 120 finished with value: 0.0 and parameters: {'num_leaves': 169, 'learning_rate': 0.0003290165178775251, 'n_estimators': 122, 'subsample': 0.728387004146676, 'colsample_bytree': 0.9406418747521484}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:48,627] Trial 121 finished with value: 0.4292782304677908 and parameters: {'num_leaves': 160, 'learning_rate': 0.06446034320607853, 'n_estimators': 132, 'subsample': 0.7134149533243246, 'colsample_bytree': 0.9010622797658216}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:51,341] Trial 122 finished with value: 0.434064243498592 and parameters: {'num_leaves': 148, 'learning_rate': 0.03963790546299734, 'n_estimators': 149, 'subsample': 0.7589124651020855, 'colsample_bytree': 0.9195277969720943}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:53,638] Trial 123 finished with value: 0.4389468047068874 and parameters: {'num_leaves': 155, 'learning_rate': 0.04947812773617022, 'n_estimators': 116, 'subsample': 0.7453549097965031, 'colsample_bytree': 0.9619515855781299}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:56,023] Trial 124 finished with value: 0.4352483542753042 and parameters: {'num_leaves': 173, 'learning_rate': 0.054516009201374255, 'n_estimators': 115, 'subsample': 0.7913528577388598, 'colsample_bytree': 0.9611855868924563}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:23:58,040] Trial 125 finished with value: 0.4356375087222631 and parameters: {'num_leaves': 154, 'learning_rate': 0.0777904074618681, 'n_estimators': 107, 'subsample': 0.7467229617226747, 'colsample_bytree': 0.9839683735950877}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:00,200] Trial 126 finished with value: 0.4370466728866148 and parameters: {'num_leaves': 135, 'learning_rate': 0.031043248096310757, 'n_estimators': 126, 'subsample': 0.7775642860450284, 'colsample_bytree': 0.9988117753764603}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:02,987] Trial 127 finished with value: 0.424216500146908 and parameters: {'num_leaves': 164, 'learning_rate': 0.02159070315853513, 'n_estimators': 143, 'subsample': 0.8253646260384326, 'colsample_bytree': 0.9589413344291416}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:05,469] Trial 128 finished with value: 0.43488352813476777 and parameters: {'num_leaves': 147, 'learning_rate': 0.04800283332960311, 'n_estimators': 136, 'subsample': 0.7331544783657239, 'colsample_bytree': 0.9388476152428712}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:07,232] Trial 129 finished with value: 0.43551918164885467 and parameters: {'num_leaves': 123, 'learning_rate': 0.06881194855017228, 'n_estimators': 116, 'subsample': 0.8427508632940508, 'colsample_bytree': 0.9734820826582519}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:09,058] Trial 130 finished with value: 0.433946363082072 and parameters: {'num_leaves': 144, 'learning_rate': 0.08791285209847334, 'n_estimators': 101, 'subsample': 0.7612674586442327, 'colsample_bytree': 0.9185722161379142}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:11,270] Trial 131 finished with value: 0.435256455221363 and parameters: {'num_leaves': 135, 'learning_rate': 0.030418007331073024, 'n_estimators': 128, 'subsample': 0.7786082872841288, 'colsample_bytree': 0.9496014869699103}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:13,106] Trial 132 finished with value: 0.4329031826824273 and parameters: {'num_leaves': 111, 'learning_rate': 0.03176301682106341, 'n_estimators': 123, 'subsample': 0.7672894463612949, 'colsample_bytree': 0.9855349130896004}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:15,043] Trial 133 finished with value: 0.4135576050097849 and parameters: {'num_leaves': 136, 'learning_rate': 0.025216107034696265, 'n_estimators': 110, 'subsample': 0.7432819958229604, 'colsample_bytree': 0.9672634146277411}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:17,886] Trial 134 finished with value: 0.43796471526499986 and parameters: {'num_leaves': 155, 'learning_rate': 0.03952618277922936, 'n_estimators': 151, 'subsample': 0.8049772890545861, 'colsample_bytree': 0.9887006320545885}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:20,740] Trial 135 finished with value: 0.4361886892185164 and parameters: {'num_leaves': 156, 'learning_rate': 0.038923465400785694, 'n_estimators': 151, 'subsample': 0.8037258076323217, 'colsample_bytree': 0.9984392379795048}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:23,655] Trial 136 finished with value: 0.43529901341956895 and parameters: {'num_leaves': 177, 'learning_rate': 0.05679942152236485, 'n_estimators': 140, 'subsample': 0.8149215551886886, 'colsample_bytree': 0.9316530621706527}. Best is trial 85 with value: 0.4467462624452061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 14:24:25,319] Trial 137 finished with value: 0.21501393094225518 and parameters: {'num_leaves': 169, 'learning_rate': 0.04289681479846222, 'n_estimators': 133, 'subsample': 0.853911279815252, 'colsample_bytree': 0.10596678690598671}. Best is trial 85 with value: 0.4467462624452061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 14:24:28,264] Trial 138 finished with value: 0.4253170754108201 and parameters: {'num_leaves': 150, 'learning_rate': 0.0667515205844433, 'n_estimators': 164, 'subsample': 0.789368108634213, 'colsample_bytree': 0.9530996128477157}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:31,196] Trial 139 finished with value: 0.43416002384769764 and parameters: {'num_leaves': 160, 'learning_rate': 0.049501415586664106, 'n_estimators': 155, 'subsample': 0.7193332273273081, 'colsample_bytree': 0.9764390035311437}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:34,111] Trial 140 finished with value: 0.4386415928375353 and parameters: {'num_leaves': 166, 'learning_rate': 0.03611217794912772, 'n_estimators': 146, 'subsample': 0.8307265927817732, 'colsample_bytree': 0.883709917183686}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:37,013] Trial 141 finished with value: 0.43417827188834063 and parameters: {'num_leaves': 165, 'learning_rate': 0.036818057488031006, 'n_estimators': 146, 'subsample': 0.8326972411608239, 'colsample_bytree': 0.8874204503111118}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:39,590] Trial 142 finished with value: 0.42728529218975053 and parameters: {'num_leaves': 186, 'learning_rate': 0.02635315831289008, 'n_estimators': 117, 'subsample': 0.8634357071983836, 'colsample_bytree': 0.9156382195899301}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:42,208] Trial 143 finished with value: 0.43604818216931873 and parameters: {'num_leaves': 172, 'learning_rate': 0.05267426304601144, 'n_estimators': 128, 'subsample': 0.8377234280174953, 'colsample_bytree': 0.9413384625836747}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:44,339] Trial 144 finished with value: 0.4381331290165771 and parameters: {'num_leaves': 155, 'learning_rate': 0.03719697428818989, 'n_estimators': 109, 'subsample': 0.7975834601326828, 'colsample_bytree': 0.9647117705010502}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:46,922] Trial 145 finished with value: 0.43293636817590786 and parameters: {'num_leaves': 151, 'learning_rate': 0.021897683600430925, 'n_estimators': 138, 'subsample': 0.8238272521876121, 'colsample_bytree': 0.9846718624453475}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:48,780] Trial 146 finished with value: 0.43118945498975336 and parameters: {'num_leaves': 143, 'learning_rate': 0.035045869703647856, 'n_estimators': 100, 'subsample': 0.794739105549269, 'colsample_bytree': 0.9298552446959698}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:50,897] Trial 147 finished with value: 0.42586091498602385 and parameters: {'num_leaves': 156, 'learning_rate': 0.05962926758597246, 'n_estimators': 108, 'subsample': 0.8014525828661105, 'colsample_bytree': 0.8687095853864895}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:53,575] Trial 148 finished with value: 0.4362438759095263 and parameters: {'num_leaves': 128, 'learning_rate': 0.027470071054480398, 'n_estimators': 162, 'subsample': 0.8154152934921909, 'colsample_bytree': 0.9695888056658778}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:24:56,865] Trial 149 finished with value: 0.0 and parameters: {'num_leaves': 164, 'learning_rate': 3.48958380928273e-05, 'n_estimators': 181, 'subsample': 0.770645622138305, 'colsample_bytree': 0.9490794938075044}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:00,159] Trial 150 finished with value: 0.4217792107481112 and parameters: {'num_leaves': 139, 'learning_rate': 0.08471548391533353, 'n_estimators': 201, 'subsample': 0.8094216201919995, 'colsample_bytree': 0.9998418130843367}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:02,710] Trial 151 finished with value: 0.4425154438506044 and parameters: {'num_leaves': 181, 'learning_rate': 0.040466844507626144, 'n_estimators': 119, 'subsample': 0.7514437010313625, 'colsample_bytree': 0.9618791070338152}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:05,305] Trial 152 finished with value: 0.43754692416714613 and parameters: {'num_leaves': 179, 'learning_rate': 0.04122516541750976, 'n_estimators': 121, 'subsample': 0.7546759296139157, 'colsample_bytree': 0.9058945504761172}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:07,830] Trial 153 finished with value: 0.4372731884428365 and parameters: {'num_leaves': 161, 'learning_rate': 0.04480228543847047, 'n_estimators': 131, 'subsample': 0.7873416930427624, 'colsample_bytree': 0.9781480975562158}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:09,959] Trial 154 finished with value: 0.4365819210572006 and parameters: {'num_leaves': 156, 'learning_rate': 0.0695644624944834, 'n_estimators': 110, 'subsample': 0.7314865945137397, 'colsample_bytree': 0.954508520930392}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:12,892] Trial 155 finished with value: 0.436858738448627 and parameters: {'num_leaves': 168, 'learning_rate': 0.034809373898661934, 'n_estimators': 147, 'subsample': 0.776632624601782, 'colsample_bytree': 0.9335817836131162}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:15,143] Trial 156 finished with value: 0.3962549829564931 and parameters: {'num_leaves': 146, 'learning_rate': 0.01883335323139217, 'n_estimators': 123, 'subsample': 0.7605647752019743, 'colsample_bytree': 0.9668967069437736}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:17,545] Trial 157 finished with value: 0.42744601277145355 and parameters: {'num_leaves': 152, 'learning_rate': 0.061268357508587126, 'n_estimators': 133, 'subsample': 0.7374581973543551, 'colsample_bytree': 0.9872229658968852}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:19,979] Trial 158 finished with value: 0.42793332060632006 and parameters: {'num_leaves': 183, 'learning_rate': 0.028878710953362807, 'n_estimators': 115, 'subsample': 0.8293210831329181, 'colsample_bytree': 0.918692176339016}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:22,235] Trial 159 finished with value: 0.4323312517210507 and parameters: {'num_leaves': 189, 'learning_rate': 0.04057488431717928, 'n_estimators': 100, 'subsample': 0.6958899774232401, 'colsample_bytree': 0.9431786203465902}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:24,917] Trial 160 finished with value: 0.42704271002084554 and parameters: {'num_leaves': 160, 'learning_rate': 0.0537804009977267, 'n_estimators': 139, 'subsample': 0.8006591758138366, 'colsample_bytree': 0.8942865336368566}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:27,555] Trial 161 finished with value: 0.4367974336870272 and parameters: {'num_leaves': 179, 'learning_rate': 0.041105942791062756, 'n_estimators': 122, 'subsample': 0.753681119217711, 'colsample_bytree': 0.9028477200809816}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:29,906] Trial 162 finished with value: 0.43998563537673496 and parameters: {'num_leaves': 179, 'learning_rate': 0.035697938568817984, 'n_estimators': 108, 'subsample': 0.7683364423074929, 'colsample_bytree': 0.9615278872787857}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:32,521] Trial 163 finished with value: 0.43041464552565956 and parameters: {'num_leaves': 196, 'learning_rate': 0.03332368259342897, 'n_estimators': 113, 'subsample': 0.7807986491764346, 'colsample_bytree': 0.9648097791641841}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:34,832] Trial 164 finished with value: 0.41190569273795025 and parameters: {'num_leaves': 171, 'learning_rate': 0.02362757766812674, 'n_estimators': 111, 'subsample': 0.767013634552551, 'colsample_bytree': 0.9519789287946181}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:36,989] Trial 165 finished with value: 0.43856781716008586 and parameters: {'num_leaves': 166, 'learning_rate': 0.04918142006773732, 'n_estimators': 106, 'subsample': 0.7445860927396658, 'colsample_bytree': 0.9822025986609026}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:39,213] Trial 166 finished with value: 0.414839916601309 and parameters: {'num_leaves': 154, 'learning_rate': 0.04784573904870619, 'n_estimators': 127, 'subsample': 0.742126086878701, 'colsample_bytree': 0.6476259057761333}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:41,170] Trial 167 finished with value: 0.0 and parameters: {'num_leaves': 168, 'learning_rate': 0.0007423127977262297, 'n_estimators': 102, 'subsample': 0.7227071486201209, 'colsample_bytree': 0.9834484970757429}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:44,230] Trial 168 finished with value: 0.4361220992473497 and parameters: {'num_leaves': 164, 'learning_rate': 0.034403674124667244, 'n_estimators': 153, 'subsample': 0.7559226744274232, 'colsample_bytree': 0.9821320354748666}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:46,175] Trial 169 finished with value: 0.4212796031049709 and parameters: {'num_leaves': 149, 'learning_rate': 0.0279552320139983, 'n_estimators': 106, 'subsample': 0.7283996980556748, 'colsample_bytree': 0.9351645456213008}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:48,816] Trial 170 finished with value: 0.43692369937972914 and parameters: {'num_leaves': 158, 'learning_rate': 0.046944263926944264, 'n_estimators': 142, 'subsample': 0.7434662175589747, 'colsample_bytree': 0.9986684624476772}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:51,410] Trial 171 finished with value: 0.4302508709384152 and parameters: {'num_leaves': 181, 'learning_rate': 0.071145418027001, 'n_estimators': 119, 'subsample': 0.7675748071480711, 'colsample_bytree': 0.9633716887053233}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:53,698] Trial 172 finished with value: 0.4337261158703389 and parameters: {'num_leaves': 175, 'learning_rate': 0.05807596884101441, 'n_estimators': 109, 'subsample': 0.7899755243550401, 'colsample_bytree': 0.9685779068557413}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:55,900] Trial 173 finished with value: 0.3614542996273606 and parameters: {'num_leaves': 172, 'learning_rate': 0.03853454036186381, 'n_estimators': 129, 'subsample': 0.8093951835741887, 'colsample_bytree': 0.38329073966837846}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:25:58,249] Trial 174 finished with value: 0.4330346504846319 and parameters: {'num_leaves': 164, 'learning_rate': 0.07456703082655435, 'n_estimators': 120, 'subsample': 0.7713872149201271, 'colsample_bytree': 0.9999096936987983}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:00,557] Trial 175 finished with value: 0.4262513774307296 and parameters: {'num_leaves': 142, 'learning_rate': 0.09354217321730646, 'n_estimators': 135, 'subsample': 0.7506911580619677, 'colsample_bytree': 0.949598360425261}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:03,080] Trial 176 finished with value: 0.44114097023007603 and parameters: {'num_leaves': 189, 'learning_rate': 0.05476678101946025, 'n_estimators': 112, 'subsample': 0.8183092750739962, 'colsample_bytree': 0.9265845109149193}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:05,633] Trial 177 finished with value: 0.44132508390775327 and parameters: {'num_leaves': 187, 'learning_rate': 0.049115746047209065, 'n_estimators': 110, 'subsample': 0.8416990116565934, 'colsample_bytree': 0.9257114881299399}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:10,993] Trial 178 finished with value: 0.42209278540145395 and parameters: {'num_leaves': 190, 'learning_rate': 0.053900121666018534, 'n_estimators': 248, 'subsample': 0.8626647984424759, 'colsample_bytree': 0.9206118055222793}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:13,168] Trial 179 finished with value: 0.3924915783983944 and parameters: {'num_leaves': 204, 'learning_rate': 0.046564648268757156, 'n_estimators': 100, 'subsample': 0.8774716109387989, 'colsample_bytree': 0.5889915882352368}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:15,568] Trial 180 finished with value: 0.4234312292648766 and parameters: {'num_leaves': 186, 'learning_rate': 0.03199006000833646, 'n_estimators': 108, 'subsample': 0.8222545675682041, 'colsample_bytree': 0.8825750578782736}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:18,195] Trial 181 finished with value: 0.44508034011376046 and parameters: {'num_leaves': 194, 'learning_rate': 0.038824844157358054, 'n_estimators': 116, 'subsample': 0.8468489924380874, 'colsample_bytree': 0.9347437821887218}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:20,819] Trial 182 finished with value: 0.4353560108747496 and parameters: {'num_leaves': 195, 'learning_rate': 0.05736173871940765, 'n_estimators': 114, 'subsample': 0.8499851475686554, 'colsample_bytree': 0.929876202520937}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:26,680] Trial 183 finished with value: 0.42765092676483435 and parameters: {'num_leaves': 184, 'learning_rate': 0.046191235184727564, 'n_estimators': 284, 'subsample': 0.8446824995011781, 'colsample_bytree': 0.9404231699543761}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:29,340] Trial 184 finished with value: 0.0 and parameters: {'num_leaves': 192, 'learning_rate': 0.0036220532214830707, 'n_estimators': 125, 'subsample': 0.8438865319845014, 'colsample_bytree': 0.9110099740803556}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:31,958] Trial 185 finished with value: 0.43973868016429485 and parameters: {'num_leaves': 211, 'learning_rate': 0.03532603960858089, 'n_estimators': 107, 'subsample': 0.8356419404083886, 'colsample_bytree': 0.9525410912536227}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:34,842] Trial 186 finished with value: 0.42087316204492203 and parameters: {'num_leaves': 211, 'learning_rate': 0.026218905231205684, 'n_estimators': 117, 'subsample': 0.8363033063090783, 'colsample_bytree': 0.9252163540745462}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:37,657] Trial 187 finished with value: 0.43429868656444703 and parameters: {'num_leaves': 229, 'learning_rate': 0.06557086344519635, 'n_estimators': 107, 'subsample': 0.8197148107937157, 'colsample_bytree': 0.9489802498253056}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:40,596] Trial 188 finished with value: 0.44020882428369823 and parameters: {'num_leaves': 202, 'learning_rate': 0.030706775556068606, 'n_estimators': 125, 'subsample': 0.8555550320498091, 'colsample_bytree': 0.9719780697645132}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:43,640] Trial 189 finished with value: 0.43432392901330896 and parameters: {'num_leaves': 214, 'learning_rate': 0.03048699398766184, 'n_estimators': 124, 'subsample': 0.8918405581136406, 'colsample_bytree': 0.9067567108994008}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:46,061] Trial 190 finished with value: 0.429411914895194 and parameters: {'num_leaves': 200, 'learning_rate': 0.03634957555335832, 'n_estimators': 100, 'subsample': 0.8613128389114133, 'colsample_bytree': 0.9382392485945846}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:48,754] Trial 191 finished with value: 0.43339052427797753 and parameters: {'num_leaves': 200, 'learning_rate': 0.047263790027365686, 'n_estimators': 115, 'subsample': 0.8351239742760069, 'colsample_bytree': 0.974555579152136}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:51,745] Trial 192 finished with value: 0.4149579994971441 and parameters: {'num_leaves': 198, 'learning_rate': 0.02047001549619975, 'n_estimators': 130, 'subsample': 0.8590609240004272, 'colsample_bytree': 0.9558096340542004}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:54,643] Trial 193 finished with value: 0.4432218502371533 and parameters: {'num_leaves': 207, 'learning_rate': 0.04093828274134769, 'n_estimators': 121, 'subsample': 0.8696264180894676, 'colsample_bytree': 0.9755192151126056}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:26:57,725] Trial 194 finished with value: 0.44241387450586594 and parameters: {'num_leaves': 215, 'learning_rate': 0.04090186459817748, 'n_estimators': 122, 'subsample': 0.872856204374849, 'colsample_bytree': 0.9778060782263157}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:27:00,733] Trial 195 finished with value: 0.42800260782388816 and parameters: {'num_leaves': 209, 'learning_rate': 0.030479015230181927, 'n_estimators': 123, 'subsample': 0.8800022364938263, 'colsample_bytree': 0.95269714880705}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:27:04,059] Trial 196 finished with value: 0.4333822782290052 and parameters: {'num_leaves': 212, 'learning_rate': 0.039837080011013604, 'n_estimators': 136, 'subsample': 0.9067083165798513, 'colsample_bytree': 0.9215917433239282}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:27:07,086] Trial 197 finished with value: 0.4228025692005638 and parameters: {'num_leaves': 223, 'learning_rate': 0.025883849886927473, 'n_estimators': 118, 'subsample': 0.8753187308321194, 'colsample_bytree': 0.9683130213264511}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:27:10,425] Trial 198 finished with value: 0.435743123969594 and parameters: {'num_leaves': 222, 'learning_rate': 0.03371793429508726, 'n_estimators': 129, 'subsample': 0.8520410167105125, 'colsample_bytree': 0.9419544535325753}. Best is trial 85 with value: 0.4467462624452061.\n",
      "[I 2024-10-31 14:27:13,160] Trial 199 finished with value: 0.4409699859376273 and parameters: {'num_leaves': 207, 'learning_rate': 0.03942144937088673, 'n_estimators': 113, 'subsample': 0.8691975874742621, 'colsample_bytree': 0.9722697893495404}. Best is trial 85 with value: 0.4467462624452061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial parameters: {'num_leaves': 156, 'learning_rate': 0.041965253111443356, 'n_estimators': 138, 'subsample': 0.8143873493140596, 'colsample_bytree': 0.9565412510447763}\n",
      "Best Matthews Correlation Coefficient: 0.4467462624452061\n",
      "train score 0.9906962962962963 \n",
      " test score 0.8801777777777777\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import joblib\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 255),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    cla = LGBMClassifier(**params)\n",
    "\n",
    "    f1score = cross_val_score(cla, train, target, cv=5, scoring='f1').mean()\n",
    "\n",
    "    return f1score\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "print(\"Best trial parameters:\", study.best_trial.params)\n",
    "print(\"Best Matthews Correlation Coefficient:\", study.best_value)\n",
    "\n",
    "# Retrieve the best parameters from the Optuna study\n",
    "best_params = study.best_params\n",
    "\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "cla = LGBMClassifier(**best_params)\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, target)\n",
    "cla.fit(x_train, y_train)\n",
    "\n",
    "train_score = cla.score(x_train, y_train)\n",
    "test_score = cla.score(x_test, y_test)\n",
    "\n",
    "joblib.dump(cla, 'lgbm_model.pkl')\n",
    "\n",
    "print(f'train score {train_score} \\n test score {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 14:27:13,712] A new study created in memory with name: no-name-992b4621-a71c-4a06-81ec-e759dd7e8087\n",
      "[I 2024-10-31 14:27:14,754] Trial 0 finished with value: 0.0 and parameters: {'num_leaves': 5, 'learning_rate': 4.5420681933389906e-05, 'n_estimators': 170, 'subsample': 0.5393336225481169, 'colsample_bytree': 0.6471513493835709}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-10-31 14:27:17,153] Trial 1 finished with value: 0.0 and parameters: {'num_leaves': 7, 'learning_rate': 0.0002687683535878209, 'n_estimators': 282, 'subsample': 0.5810701539919705, 'colsample_bytree': 0.8294699041598725}. Best is trial 0 with value: 0.0.\n",
      "[I 2024-10-31 14:27:19,304] Trial 2 finished with value: 0.4224012013255134 and parameters: {'num_leaves': 4, 'learning_rate': 0.05200453642504956, 'n_estimators': 459, 'subsample': 0.8652886129108639, 'colsample_bytree': 0.3836096983954098}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:27:24,309] Trial 3 finished with value: 0.0 and parameters: {'num_leaves': 8, 'learning_rate': 0.00029684185030663207, 'n_estimators': 491, 'subsample': 0.9615799774908289, 'colsample_bytree': 0.6929485959611494}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:27:29,883] Trial 4 finished with value: 0.0 and parameters: {'num_leaves': 13, 'learning_rate': 0.0004379542905716632, 'n_estimators': 285, 'subsample': 0.7792953818120578, 'colsample_bytree': 0.5290849223380816}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:27:31,071] Trial 5 finished with value: 0.41175381822322726 and parameters: {'num_leaves': 5, 'learning_rate': 0.04592209925636036, 'n_estimators': 203, 'subsample': 0.5534222049555653, 'colsample_bytree': 0.6060263385289864}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:27:32,747] Trial 6 finished with value: 0.28048063100562015 and parameters: {'num_leaves': 9, 'learning_rate': 0.05495356522120073, 'n_estimators': 153, 'subsample': 0.9567790972941745, 'colsample_bytree': 0.19421452743642387}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:27:39,905] Trial 7 finished with value: 0.0 and parameters: {'num_leaves': 12, 'learning_rate': 0.001142549384798188, 'n_estimators': 402, 'subsample': 0.8260329564256693, 'colsample_bytree': 0.5687744368793969}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:27:42,844] Trial 8 finished with value: 0.0 and parameters: {'num_leaves': 6, 'learning_rate': 3.4038396276392724e-05, 'n_estimators': 453, 'subsample': 0.9641412572637511, 'colsample_bytree': 0.36340604386592956}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:27:55,821] Trial 9 finished with value: 0.0 and parameters: {'num_leaves': 19, 'learning_rate': 0.0001380843865120939, 'n_estimators': 455, 'subsample': 0.6956184071740272, 'colsample_bytree': 0.7429415240820738}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:27:57,265] Trial 10 finished with value: 0.024619737868843684 and parameters: {'num_leaves': 3, 'learning_rate': 0.005152425115815308, 'n_estimators': 384, 'subsample': 0.8578993322153531, 'colsample_bytree': 0.1616654242102612}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:27:58,262] Trial 11 finished with value: 0.38946390832274447 and parameters: {'num_leaves': 3, 'learning_rate': 0.06429909193356051, 'n_estimators': 229, 'subsample': 0.6673799678021766, 'colsample_bytree': 0.9767987490082}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:28:01,195] Trial 12 finished with value: 0.012107688110847753 and parameters: {'num_leaves': 16, 'learning_rate': 0.008752116162801167, 'n_estimators': 109, 'subsample': 0.5032035383836102, 'colsample_bytree': 0.37670466055189267}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:28:06,238] Trial 13 finished with value: 0.3224071877991238 and parameters: {'num_leaves': 10, 'learning_rate': 0.01437352480332625, 'n_estimators': 347, 'subsample': 0.6625957619288916, 'colsample_bytree': 0.37024007323679675}. Best is trial 2 with value: 0.4224012013255134.\n",
      "[I 2024-10-31 14:28:07,515] Trial 14 finished with value: 0.4303374148851472 and parameters: {'num_leaves': 5, 'learning_rate': 0.09399754093586526, 'n_estimators': 219, 'subsample': 0.8814225603239442, 'colsample_bytree': 0.49067819048739153}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:08,492] Trial 15 finished with value: 0.0 and parameters: {'num_leaves': 3, 'learning_rate': 0.0030351113356642313, 'n_estimators': 239, 'subsample': 0.8795885192488095, 'colsample_bytree': 0.4685095148545905}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:13,150] Trial 16 finished with value: 0.3060935364290541 and parameters: {'num_leaves': 10, 'learning_rate': 0.019485337563200048, 'n_estimators': 325, 'subsample': 0.8986215687988747, 'colsample_bytree': 0.26068597864604537}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:21,502] Trial 17 finished with value: 0.37065702874345935 and parameters: {'num_leaves': 14, 'learning_rate': 0.030393557163197377, 'n_estimators': 383, 'subsample': 0.7852875109045557, 'colsample_bytree': 0.45941428625898967}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:23,065] Trial 18 finished with value: 0.423582888342214 and parameters: {'num_leaves': 5, 'learning_rate': 0.08857893163987124, 'n_estimators': 262, 'subsample': 0.9131703566971004, 'colsample_bytree': 0.2955475124494365}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:25,185] Trial 19 finished with value: 0.0 and parameters: {'num_leaves': 7, 'learning_rate': 0.0023852948668850824, 'n_estimators': 259, 'subsample': 0.9879470405623294, 'colsample_bytree': 0.21823572697260418}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:31,172] Trial 20 finished with value: 0.0 and parameters: {'num_leaves': 16, 'learning_rate': 1.2914657472732634e-05, 'n_estimators': 201, 'subsample': 0.9280778975692502, 'colsample_bytree': 0.26680016929007583}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:32,806] Trial 21 finished with value: 0.349151102365005 and parameters: {'num_leaves': 5, 'learning_rate': 0.058772703728619896, 'n_estimators': 310, 'subsample': 0.8060493609877989, 'colsample_bytree': 0.10590348080777862}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:34,484] Trial 22 finished with value: 0.4205110308271191 and parameters: {'num_leaves': 4, 'learning_rate': 0.0961842009274513, 'n_estimators': 353, 'subsample': 0.8493650603386014, 'colsample_bytree': 0.32438051869063217}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:35,862] Trial 23 finished with value: 0.2763950302706747 and parameters: {'num_leaves': 7, 'learning_rate': 0.01727690089611175, 'n_estimators': 151, 'subsample': 0.9120357954795184, 'colsample_bytree': 0.4534758460770332}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:37,643] Trial 24 finished with value: 0.3453738202498024 and parameters: {'num_leaves': 6, 'learning_rate': 0.028065585053340173, 'n_estimators': 254, 'subsample': 0.7325865791169902, 'colsample_bytree': 0.2988352218934201}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:40,513] Trial 25 finished with value: 0.41238482440135027 and parameters: {'num_leaves': 10, 'learning_rate': 0.09634192564099246, 'n_estimators': 203, 'subsample': 0.8663570469379733, 'colsample_bytree': 0.4172828786184669}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:42,537] Trial 26 finished with value: 0.3133280721576859 and parameters: {'num_leaves': 4, 'learning_rate': 0.008292223067304719, 'n_estimators': 434, 'subsample': 0.9230256538970962, 'colsample_bytree': 0.5105539382298203}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:47,324] Trial 27 finished with value: 0.4025207643071669 and parameters: {'num_leaves': 8, 'learning_rate': 0.03716122493533532, 'n_estimators': 496, 'subsample': 0.7435928299572122, 'colsample_bytree': 0.3290378620685504}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:48,772] Trial 28 finished with value: 0.29208781438854575 and parameters: {'num_leaves': 4, 'learning_rate': 0.012100993940804938, 'n_estimators': 288, 'subsample': 0.8303169606970147, 'colsample_bytree': 0.41660768175266816}. Best is trial 14 with value: 0.4303374148851472.\n",
      "[I 2024-10-31 14:28:49,877] Trial 29 finished with value: 0.4305665914553736 and parameters: {'num_leaves': 5, 'learning_rate': 0.09731214426492793, 'n_estimators': 178, 'subsample': 0.9942079924851076, 'colsample_bytree': 0.6479824098547227}. Best is trial 29 with value: 0.4305665914553736.\n",
      "[I 2024-10-31 14:28:50,791] Trial 30 finished with value: 0.0 and parameters: {'num_leaves': 6, 'learning_rate': 0.004288046819577704, 'n_estimators': 112, 'subsample': 0.9797584755675964, 'colsample_bytree': 0.6616220357601608}. Best is trial 29 with value: 0.4305665914553736.\n",
      "[I 2024-10-31 14:28:51,882] Trial 31 finished with value: 0.4330559237209197 and parameters: {'num_leaves': 5, 'learning_rate': 0.09805042652741634, 'n_estimators': 173, 'subsample': 0.9985891367904092, 'colsample_bytree': 0.8166094970205857}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:28:52,946] Trial 32 finished with value: 0.428425372937044 and parameters: {'num_leaves': 5, 'learning_rate': 0.09216127873776102, 'n_estimators': 173, 'subsample': 0.9950708744409882, 'colsample_bytree': 0.7829875573417425}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:28:55,176] Trial 33 finished with value: 0.40869378448236066 and parameters: {'num_leaves': 8, 'learning_rate': 0.026750872711339576, 'n_estimators': 174, 'subsample': 0.9441873607770351, 'colsample_bytree': 0.8261182605247042}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:28:56,455] Trial 34 finished with value: 0.4321261544529557 and parameters: {'num_leaves': 6, 'learning_rate': 0.0966352108183624, 'n_estimators': 169, 'subsample': 0.9870518342762434, 'colsample_bytree': 0.7907412617739114}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:28:57,566] Trial 35 finished with value: 0.40789663908443546 and parameters: {'num_leaves': 6, 'learning_rate': 0.04403250038222521, 'n_estimators': 134, 'subsample': 0.9477751875850675, 'colsample_bytree': 0.9080015154338309}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:00,129] Trial 36 finished with value: 0.0 and parameters: {'num_leaves': 8, 'learning_rate': 0.0012211914734265128, 'n_estimators': 225, 'subsample': 0.998594018107697, 'colsample_bytree': 0.7186579949493056}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:01,928] Trial 37 finished with value: 0.39565112297304905 and parameters: {'num_leaves': 7, 'learning_rate': 0.02241316774642936, 'n_estimators': 186, 'subsample': 0.8930305874876577, 'colsample_bytree': 0.8743267373191979}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:03,897] Trial 38 finished with value: 0.4236114166818664 and parameters: {'num_leaves': 9, 'learning_rate': 0.055231698975177955, 'n_estimators': 147, 'subsample': 0.9622483818949372, 'colsample_bytree': 0.6222499215002535}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:04,455] Trial 39 finished with value: 0.0 and parameters: {'num_leaves': 3, 'learning_rate': 0.00017848118680737824, 'n_estimators': 125, 'subsample': 0.9313944111354632, 'colsample_bytree': 0.5701617888149919}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:08,109] Trial 40 finished with value: 0.4162538357329676 and parameters: {'num_leaves': 11, 'learning_rate': 0.0349521416737777, 'n_estimators': 200, 'subsample': 0.97396827180435, 'colsample_bytree': 0.6696671591745986}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:09,155] Trial 41 finished with value: 0.4229428428326714 and parameters: {'num_leaves': 5, 'learning_rate': 0.09822874675947131, 'n_estimators': 171, 'subsample': 0.9885936462709345, 'colsample_bytree': 0.771370778406183}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:10,181] Trial 42 finished with value: 0.4160018508134806 and parameters: {'num_leaves': 5, 'learning_rate': 0.06312673635102999, 'n_estimators': 161, 'subsample': 0.9988899166732522, 'colsample_bytree': 0.7918231859769593}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:11,282] Trial 43 finished with value: 0.4144630162193826 and parameters: {'num_leaves': 4, 'learning_rate': 0.06536504915209629, 'n_estimators': 215, 'subsample': 0.956252871943801, 'colsample_bytree': 0.8919723133566961}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:13,029] Trial 44 finished with value: 0.4280070855017395 and parameters: {'num_leaves': 7, 'learning_rate': 0.04047629821321161, 'n_estimators': 183, 'subsample': 0.9370111581184144, 'colsample_bytree': 0.9498878818908252}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:14,077] Trial 45 finished with value: 0.0 and parameters: {'num_leaves': 6, 'learning_rate': 0.0004687262167155556, 'n_estimators': 135, 'subsample': 0.9740951083023687, 'colsample_bytree': 0.8329060496610767}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:15,089] Trial 46 finished with value: 0.40354050484267817 and parameters: {'num_leaves': 4, 'learning_rate': 0.07113157063746453, 'n_estimators': 190, 'subsample': 0.9619027332037487, 'colsample_bytree': 0.7122694470199731}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:16,888] Trial 47 finished with value: 0.4289553248143819 and parameters: {'num_leaves': 6, 'learning_rate': 0.04284973439915597, 'n_estimators': 240, 'subsample': 0.8956278561177271, 'colsample_bytree': 0.7527708138076779}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:19,912] Trial 48 finished with value: 0.2877623281378413 and parameters: {'num_leaves': 9, 'learning_rate': 0.01032880331478191, 'n_estimators': 237, 'subsample': 0.6020108422306671, 'colsample_bytree': 0.5984298881396383}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:20,996] Trial 49 finished with value: 0.0 and parameters: {'num_leaves': 3, 'learning_rate': 7.071850347481758e-05, 'n_estimators': 274, 'subsample': 0.889106406614402, 'colsample_bytree': 0.7462753622442794}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:26,230] Trial 50 finished with value: 0.4060742752523387 and parameters: {'num_leaves': 13, 'learning_rate': 0.019720853974129326, 'n_estimators': 217, 'subsample': 0.8341549868803805, 'colsample_bytree': 0.8317338626404078}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:27,310] Trial 51 finished with value: 0.40674092366942727 and parameters: {'num_leaves': 5, 'learning_rate': 0.04665853523502795, 'n_estimators': 164, 'subsample': 0.911469447671901, 'colsample_bytree': 0.7900355907419179}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:33,460] Trial 52 finished with value: 0.41312719016787414 and parameters: {'num_leaves': 20, 'learning_rate': 0.09876114965483372, 'n_estimators': 239, 'subsample': 0.9850593448226153, 'colsample_bytree': 0.6926924481101242}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:34,775] Trial 53 finished with value: 0.41961389314948044 and parameters: {'num_leaves': 6, 'learning_rate': 0.06575136361329756, 'n_estimators': 176, 'subsample': 0.9988970942716007, 'colsample_bytree': 0.5354054106729648}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:36,108] Trial 54 finished with value: 0.4146633164176423 and parameters: {'num_leaves': 7, 'learning_rate': 0.04827508961495953, 'n_estimators': 147, 'subsample': 0.7786734450064001, 'colsample_bytree': 0.6240933540342075}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:37,217] Trial 55 finished with value: 0.36626620879203725 and parameters: {'num_leaves': 4, 'learning_rate': 0.028604559882318265, 'n_estimators': 206, 'subsample': 0.867772680124647, 'colsample_bytree': 0.7486078539684647}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:38,651] Trial 56 finished with value: 0.43108634507805704 and parameters: {'num_leaves': 5, 'learning_rate': 0.07003563792017772, 'n_estimators': 246, 'subsample': 0.9457700621483508, 'colsample_bytree': 0.8669645804376906}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:40,499] Trial 57 finished with value: 0.43158856696995257 and parameters: {'num_leaves': 6, 'learning_rate': 0.06929214711618714, 'n_estimators': 250, 'subsample': 0.9435409304785566, 'colsample_bytree': 0.9478016305300737}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:41,658] Trial 58 finished with value: 0.40300633281069426 and parameters: {'num_leaves': 3, 'learning_rate': 0.0746364564680197, 'n_estimators': 277, 'subsample': 0.9399556094209909, 'colsample_bytree': 0.9665359683694001}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:52,571] Trial 59 finished with value: 0.4174416204170132 and parameters: {'num_leaves': 17, 'learning_rate': 0.014406786009017037, 'n_estimators': 301, 'subsample': 0.9671852648313235, 'colsample_bytree': 0.9448061861494591}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:55,570] Trial 60 finished with value: 0.28644491049654885 and parameters: {'num_leaves': 8, 'learning_rate': 0.007086373980851793, 'n_estimators': 253, 'subsample': 0.9240852570760131, 'colsample_bytree': 0.8603171614994637}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:57,327] Trial 61 finished with value: 0.4099106949007352 and parameters: {'num_leaves': 6, 'learning_rate': 0.04139432799267843, 'n_estimators': 244, 'subsample': 0.8977061262875283, 'colsample_bytree': 0.49679850219142896}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:29:59,355] Trial 62 finished with value: 0.42892451235378537 and parameters: {'num_leaves': 7, 'learning_rate': 0.05357418953532814, 'n_estimators': 225, 'subsample': 0.9511090574027974, 'colsample_bytree': 0.8966656712745327}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:30:01,235] Trial 63 finished with value: 0.42890460326643903 and parameters: {'num_leaves': 5, 'learning_rate': 0.07305965628351087, 'n_estimators': 320, 'subsample': 0.9085176779384111, 'colsample_bytree': 0.8197869140531168}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:30:02,453] Trial 64 finished with value: 0.42364569202334595 and parameters: {'num_leaves': 5, 'learning_rate': 0.07562068624859407, 'n_estimators': 192, 'subsample': 0.8781559656716114, 'colsample_bytree': 0.941809769952792}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:30:04,429] Trial 65 finished with value: 0.4165933835952794 and parameters: {'num_leaves': 6, 'learning_rate': 0.03189211472346152, 'n_estimators': 267, 'subsample': 0.9710127924222356, 'colsample_bytree': 0.9944122888163008}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:30:05,547] Trial 66 finished with value: 0.3590347975981484 and parameters: {'num_leaves': 4, 'learning_rate': 0.02321606707247636, 'n_estimators': 217, 'subsample': 0.9234486651752937, 'colsample_bytree': 0.9212305565841074}. Best is trial 31 with value: 0.4330559237209197.\n",
      "[I 2024-10-31 14:30:07,694] Trial 67 finished with value: 0.43457639872739967 and parameters: {'num_leaves': 6, 'learning_rate': 0.04903396453903085, 'n_estimators': 295, 'subsample': 0.7118394631481141, 'colsample_bytree': 0.8576504205775668}. Best is trial 67 with value: 0.43457639872739967.\n",
      "[I 2024-10-31 14:30:10,906] Trial 68 finished with value: 0.41826681022412693 and parameters: {'num_leaves': 7, 'learning_rate': 0.015986494929357595, 'n_estimators': 348, 'subsample': 0.6104876168833193, 'colsample_bytree': 0.8677298995987724}. Best is trial 67 with value: 0.43457639872739967.\n",
      "[I 2024-10-31 14:30:12,524] Trial 69 finished with value: 0.4161872760635511 and parameters: {'num_leaves': 4, 'learning_rate': 0.05427562159257481, 'n_estimators': 301, 'subsample': 0.6756100421625648, 'colsample_bytree': 0.8460287847344624}. Best is trial 67 with value: 0.43457639872739967.\n",
      "[I 2024-10-31 14:30:14,160] Trial 70 finished with value: 0.4045363371438319 and parameters: {'num_leaves': 5, 'learning_rate': 0.030329984883324862, 'n_estimators': 256, 'subsample': 0.6807550918357692, 'colsample_bytree': 0.8105246791395753}. Best is trial 67 with value: 0.43457639872739967.\n",
      "[I 2024-10-31 14:30:15,965] Trial 71 finished with value: 0.43297499803897016 and parameters: {'num_leaves': 6, 'learning_rate': 0.0782123951155853, 'n_estimators': 245, 'subsample': 0.7248370719981801, 'colsample_bytree': 0.7620918971754447}. Best is trial 67 with value: 0.43457639872739967.\n",
      "[I 2024-10-31 14:30:18,050] Trial 72 finished with value: 0.4373827691138505 and parameters: {'num_leaves': 6, 'learning_rate': 0.07446245832272771, 'n_estimators': 286, 'subsample': 0.7240648612312748, 'colsample_bytree': 0.9217695803322066}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:21,071] Trial 73 finished with value: 0.4295262152721411 and parameters: {'num_leaves': 8, 'learning_rate': 0.07835465805318204, 'n_estimators': 289, 'subsample': 0.6987482982253667, 'colsample_bytree': 0.9237138164929284}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:25,175] Trial 74 finished with value: 0.4356510963147452 and parameters: {'num_leaves': 9, 'learning_rate': 0.05769464325239545, 'n_estimators': 331, 'subsample': 0.7204211580369175, 'colsample_bytree': 0.8764042547002024}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:29,429] Trial 75 finished with value: 0.4225066730347846 and parameters: {'num_leaves': 9, 'learning_rate': 0.03644068829070395, 'n_estimators': 336, 'subsample': 0.719444115277804, 'colsample_bytree': 0.8785167314648029}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:36,215] Trial 76 finished with value: 0.00202020202020202 and parameters: {'num_leaves': 11, 'learning_rate': 0.0017005666485464409, 'n_estimators': 361, 'subsample': 0.7588083900800451, 'colsample_bytree': 0.9721907772627483}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:39,384] Trial 77 finished with value: 0.4291267393509532 and parameters: {'num_leaves': 8, 'learning_rate': 0.05827647207672542, 'n_estimators': 290, 'subsample': 0.6529728063804356, 'colsample_bytree': 0.9964315826759887}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:41,859] Trial 78 finished with value: 0.4179794352916407 and parameters: {'num_leaves': 6, 'learning_rate': 0.021092459335802734, 'n_estimators': 317, 'subsample': 0.7143779616599676, 'colsample_bytree': 0.9292419919473123}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:44,932] Trial 79 finished with value: 0.4316016778866586 and parameters: {'num_leaves': 7, 'learning_rate': 0.05146089183413082, 'n_estimators': 330, 'subsample': 0.7530385028470501, 'colsample_bytree': 0.8511845970876581}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:47,940] Trial 80 finished with value: 0.0 and parameters: {'num_leaves': 7, 'learning_rate': 2.0672182702363415e-05, 'n_estimators': 333, 'subsample': 0.7601392693377206, 'colsample_bytree': 0.8016059617428458}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:51,852] Trial 81 finished with value: 0.4205786711061325 and parameters: {'num_leaves': 9, 'learning_rate': 0.04769531998194495, 'n_estimators': 310, 'subsample': 0.6425446320062393, 'colsample_bytree': 0.8519609989491812}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:54,354] Trial 82 finished with value: 0.4339761068711986 and parameters: {'num_leaves': 7, 'learning_rate': 0.0751755508535166, 'n_estimators': 272, 'subsample': 0.7375885449113248, 'colsample_bytree': 0.8919280575227446}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:30:56,808] Trial 83 finished with value: 0.4313633381428378 and parameters: {'num_leaves': 6, 'learning_rate': 0.03592823847824158, 'n_estimators': 334, 'subsample': 0.7273819016309665, 'colsample_bytree': 0.9025836280368904}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:31:00,056] Trial 84 finished with value: 0.4244251545202398 and parameters: {'num_leaves': 7, 'learning_rate': 0.025914734522999094, 'n_estimators': 364, 'subsample': 0.692469784147119, 'colsample_bytree': 0.767181122769701}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:31:04,960] Trial 85 finished with value: 0.42286332753426203 and parameters: {'num_leaves': 10, 'learning_rate': 0.08173935989971787, 'n_estimators': 375, 'subsample': 0.7437806121041804, 'colsample_bytree': 0.8924827766512877}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:31:07,299] Trial 86 finished with value: 0.4325583043188 and parameters: {'num_leaves': 7, 'learning_rate': 0.04947661448838422, 'n_estimators': 266, 'subsample': 0.8069043807299454, 'colsample_bytree': 0.7181724619998728}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:31:10,235] Trial 87 finished with value: 0.42862028948391223 and parameters: {'num_leaves': 8, 'learning_rate': 0.05830047447052069, 'n_estimators': 268, 'subsample': 0.7783659641250091, 'colsample_bytree': 0.8469786881228328}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:31:12,782] Trial 88 finished with value: 0.4259243363085915 and parameters: {'num_leaves': 7, 'learning_rate': 0.09952164302071141, 'n_estimators': 298, 'subsample': 0.7020401081363632, 'colsample_bytree': 0.7146094321322124}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:31:17,775] Trial 89 finished with value: 0.41441885327586725 and parameters: {'num_leaves': 9, 'learning_rate': 0.04696940719753114, 'n_estimators': 419, 'subsample': 0.7979894178399298, 'colsample_bytree': 0.769390129422482}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:31:20,199] Trial 90 finished with value: 0.0 and parameters: {'num_leaves': 7, 'learning_rate': 0.0004881035280565177, 'n_estimators': 281, 'subsample': 0.7645746598503479, 'colsample_bytree': 0.8118966786254928}. Best is trial 72 with value: 0.4373827691138505.\n",
      "[I 2024-10-31 14:31:22,338] Trial 91 finished with value: 0.44255988158914905 and parameters: {'num_leaves': 6, 'learning_rate': 0.07790209305862482, 'n_estimators': 297, 'subsample': 0.7312925812321919, 'colsample_bytree': 0.9620033576037471}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:24,590] Trial 92 finished with value: 0.4332569807308747 and parameters: {'num_leaves': 6, 'learning_rate': 0.08508441212359096, 'n_estimators': 311, 'subsample': 0.7100897077356207, 'colsample_bytree': 0.9168555905684401}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:26,844] Trial 93 finished with value: 0.4272135502253883 and parameters: {'num_leaves': 6, 'learning_rate': 0.036470405049844994, 'n_estimators': 312, 'subsample': 0.7112129042069048, 'colsample_bytree': 0.9166732243211063}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:28,918] Trial 94 finished with value: 0.4356123805546169 and parameters: {'num_leaves': 6, 'learning_rate': 0.08158402624465369, 'n_estimators': 297, 'subsample': 0.7337172081430586, 'colsample_bytree': 0.8799744173686276}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:31,957] Trial 95 finished with value: 0.4285069282298994 and parameters: {'num_leaves': 8, 'learning_rate': 0.07905688245962851, 'n_estimators': 298, 'subsample': 0.7282691901719489, 'colsample_bytree': 0.8853316635563868}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:33,850] Trial 96 finished with value: 0.43455303498910036 and parameters: {'num_leaves': 6, 'learning_rate': 0.05986030564406058, 'n_estimators': 267, 'subsample': 0.7398322836648027, 'colsample_bytree': 0.9700055931158421}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:35,514] Trial 97 finished with value: 0.43714746998808174 and parameters: {'num_leaves': 5, 'learning_rate': 0.06372761260218211, 'n_estimators': 286, 'subsample': 0.7351361798097726, 'colsample_bytree': 0.9593199491516754}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:37,665] Trial 98 finished with value: 0.43399044110009255 and parameters: {'num_leaves': 5, 'learning_rate': 0.05990511806154905, 'n_estimators': 343, 'subsample': 0.7411805313641955, 'colsample_bytree': 0.9662900514972231}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:39,315] Trial 99 finished with value: 0.4257094342010313 and parameters: {'num_leaves': 4, 'learning_rate': 0.05987068226024469, 'n_estimators': 342, 'subsample': 0.7416244754393031, 'colsample_bytree': 0.9693302322041726}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:41,173] Trial 100 finished with value: 0.4194740428900242 and parameters: {'num_leaves': 5, 'learning_rate': 0.03970073161301141, 'n_estimators': 284, 'subsample': 0.7683180691001895, 'colsample_bytree': 0.9842328825484005}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:43,114] Trial 101 finished with value: 0.4233466530922511 and parameters: {'num_leaves': 5, 'learning_rate': 0.06143390218428656, 'n_estimators': 316, 'subsample': 0.7341114660421811, 'colsample_bytree': 0.963696567835593}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:45,156] Trial 102 finished with value: 0.433313477433401 and parameters: {'num_leaves': 5, 'learning_rate': 0.08482679723429841, 'n_estimators': 325, 'subsample': 0.685970829551146, 'colsample_bytree': 0.9350535147324336}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:47,277] Trial 103 finished with value: 0.4325565775190867 and parameters: {'num_leaves': 6, 'learning_rate': 0.08472966047558296, 'n_estimators': 291, 'subsample': 0.687303192226807, 'colsample_bytree': 0.9359682249747658}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:49,196] Trial 104 finished with value: 0.4298576792074198 and parameters: {'num_leaves': 5, 'learning_rate': 0.06373263906666538, 'n_estimators': 307, 'subsample': 0.7072540945222886, 'colsample_bytree': 0.9572791147766995}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:51,616] Trial 105 finished with value: 0.4186682517952426 and parameters: {'num_leaves': 6, 'learning_rate': 0.02620922347982459, 'n_estimators': 324, 'subsample': 0.7377068325471617, 'colsample_bytree': 0.9168674534553176}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:53,045] Trial 106 finished with value: 0.4136917164860826 and parameters: {'num_leaves': 4, 'learning_rate': 0.04240527768052464, 'n_estimators': 276, 'subsample': 0.6645934037165017, 'colsample_bytree': 0.9063336321757437}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:55,051] Trial 107 finished with value: 0.42348410883762283 and parameters: {'num_leaves': 5, 'learning_rate': 0.031882863195933246, 'n_estimators': 324, 'subsample': 0.7185569686888329, 'colsample_bytree': 0.9796211141307513}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:56,921] Trial 108 finished with value: 0.4355534382120772 and parameters: {'num_leaves': 5, 'learning_rate': 0.08385255224439808, 'n_estimators': 305, 'subsample': 0.7511343952765255, 'colsample_bytree': 0.9369665444063613}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:31:58,741] Trial 109 finished with value: 0.43210073910115093 and parameters: {'num_leaves': 4, 'learning_rate': 0.06806087295729507, 'n_estimators': 358, 'subsample': 0.7941677140859353, 'colsample_bytree': 0.9971272202927943}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:00,017] Trial 110 finished with value: 0.3973188618655822 and parameters: {'num_leaves': 3, 'learning_rate': 0.05030585630222486, 'n_estimators': 295, 'subsample': 0.7494457962815785, 'colsample_bytree': 0.9398402596210811}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:01,862] Trial 111 finished with value: 0.4387693979255043 and parameters: {'num_leaves': 5, 'learning_rate': 0.08510965409417251, 'n_estimators': 306, 'subsample': 0.7036941732352515, 'colsample_bytree': 0.8796103782320468}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:03,716] Trial 112 finished with value: 0.43701064408538415 and parameters: {'num_leaves': 5, 'learning_rate': 0.08512366000922221, 'n_estimators': 306, 'subsample': 0.7500639220333978, 'colsample_bytree': 0.9552161584147223}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:05,055] Trial 113 finished with value: 0.42121872517494524 and parameters: {'num_leaves': 4, 'learning_rate': 0.06107771818951016, 'n_estimators': 272, 'subsample': 0.7706310397879677, 'colsample_bytree': 0.9572733457577253}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:06,830] Trial 114 finished with value: 0.4242046748075395 and parameters: {'num_leaves': 5, 'learning_rate': 0.0437504933388131, 'n_estimators': 305, 'subsample': 0.7520393385947179, 'colsample_bytree': 0.8828954450630421}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:09,345] Trial 115 finished with value: 0.43435772923001076 and parameters: {'num_leaves': 6, 'learning_rate': 0.09764995092689607, 'n_estimators': 342, 'subsample': 0.7303496107091196, 'colsample_bytree': 0.893465295887709}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:15,180] Trial 116 finished with value: 0.41976836117813326 and parameters: {'num_leaves': 14, 'learning_rate': 0.09759237563648904, 'n_estimators': 345, 'subsample': 0.7023933897926353, 'colsample_bytree': 0.9818883133693844}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:17,844] Trial 117 finished with value: 0.43707627685197475 and parameters: {'num_leaves': 6, 'learning_rate': 0.05712028891050717, 'n_estimators': 371, 'subsample': 0.7224353142911328, 'colsample_bytree': 0.9555498937748289}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:20,500] Trial 118 finished with value: 0.4344927981712748 and parameters: {'num_leaves': 6, 'learning_rate': 0.08300988892005907, 'n_estimators': 373, 'subsample': 0.7192126660414454, 'colsample_bytree': 0.8701049162605963}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:23,272] Trial 119 finished with value: 0.0 and parameters: {'num_leaves': 6, 'learning_rate': 8.252152340730173e-05, 'n_estimators': 388, 'subsample': 0.6763173037352113, 'colsample_bytree': 0.8734003927777255}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:24,765] Trial 120 finished with value: 0.398990249122131 and parameters: {'num_leaves': 4, 'learning_rate': 0.03335582390225394, 'n_estimators': 284, 'subsample': 0.7177605344921841, 'colsample_bytree': 0.8356359933759908}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:27,550] Trial 121 finished with value: 0.4375660787066332 and parameters: {'num_leaves': 6, 'learning_rate': 0.07103989247196443, 'n_estimators': 383, 'subsample': 0.7327299029705838, 'colsample_bytree': 0.909242953141277}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:29,934] Trial 122 finished with value: 0.4290804662482584 and parameters: {'num_leaves': 5, 'learning_rate': 0.0706859671371519, 'n_estimators': 409, 'subsample': 0.6949419914349821, 'colsample_bytree': 0.9272543349122382}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:32,670] Trial 123 finished with value: 0.4384504612415704 and parameters: {'num_leaves': 6, 'learning_rate': 0.053253322423250773, 'n_estimators': 381, 'subsample': 0.7224024772698479, 'colsample_bytree': 0.9453842506937011}. Best is trial 91 with value: 0.44255988158914905.\n",
      "[I 2024-10-31 14:32:35,312] Trial 124 finished with value: 0.44349071952527447 and parameters: {'num_leaves': 6, 'learning_rate': 0.05127415123682385, 'n_estimators': 378, 'subsample': 0.7530918704036633, 'colsample_bytree': 0.9512441978096822}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:32:38,707] Trial 125 finished with value: 0.429807252898258 and parameters: {'num_leaves': 7, 'learning_rate': 0.049592398638084956, 'n_estimators': 392, 'subsample': 0.7555568460727571, 'colsample_bytree': 0.9101373583983718}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:32:40,996] Trial 126 finished with value: 0.42222525355104923 and parameters: {'num_leaves': 5, 'learning_rate': 0.041845353699504845, 'n_estimators': 394, 'subsample': 0.7879565810637771, 'colsample_bytree': 0.9536458492715116}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:32:43,640] Trial 127 finished with value: 0.4390123752663747 and parameters: {'num_leaves': 6, 'learning_rate': 0.054519401046682424, 'n_estimators': 378, 'subsample': 0.7717860165850382, 'colsample_bytree': 0.9427397518945473}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:32:45,815] Trial 128 finished with value: 0.4320681617483929 and parameters: {'num_leaves': 5, 'learning_rate': 0.07037615120566464, 'n_estimators': 375, 'subsample': 0.7715046643915623, 'colsample_bytree': 0.946605869709867}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:32:48,729] Trial 129 finished with value: 0.2016657974871483 and parameters: {'num_leaves': 6, 'learning_rate': 0.0034881026640677256, 'n_estimators': 401, 'subsample': 0.7505470415699973, 'colsample_bytree': 0.9317384521611934}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:32:52,740] Trial 130 finished with value: 0.4376627548585004 and parameters: {'num_leaves': 7, 'learning_rate': 0.02487787530548077, 'n_estimators': 477, 'subsample': 0.8160507050106951, 'colsample_bytree': 0.9939938821268455}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:32:56,564] Trial 131 finished with value: 0.43665994574087985 and parameters: {'num_leaves': 7, 'learning_rate': 0.053613858333216115, 'n_estimators': 449, 'subsample': 0.8487646414379517, 'colsample_bytree': 0.9536151799173702}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:00,718] Trial 132 finished with value: 0.43659772262555324 and parameters: {'num_leaves': 7, 'learning_rate': 0.03653533171438957, 'n_estimators': 487, 'subsample': 0.8515551949391409, 'colsample_bytree': 0.9912081846314864}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:04,899] Trial 133 finished with value: 0.4344108618001242 and parameters: {'num_leaves': 7, 'learning_rate': 0.018658175516144522, 'n_estimators': 468, 'subsample': 0.8434048782050627, 'colsample_bytree': 0.9962300495935841}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:09,076] Trial 134 finished with value: 0.4292540820400359 and parameters: {'num_leaves': 7, 'learning_rate': 0.02795398969631997, 'n_estimators': 478, 'subsample': 0.8187556384875234, 'colsample_bytree': 0.984833172650744}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:12,930] Trial 135 finished with value: 0.4357478983939411 and parameters: {'num_leaves': 7, 'learning_rate': 0.036832614102788395, 'n_estimators': 444, 'subsample': 0.8563751996750263, 'colsample_bytree': 0.953862885898647}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:17,589] Trial 136 finished with value: 0.43243817786337574 and parameters: {'num_leaves': 8, 'learning_rate': 0.024391455461520484, 'n_estimators': 445, 'subsample': 0.8396242616853485, 'colsample_bytree': 0.9991161034228794}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:21,703] Trial 137 finished with value: 0.43496233429298015 and parameters: {'num_leaves': 7, 'learning_rate': 0.035456562541283605, 'n_estimators': 489, 'subsample': 0.8586337309129584, 'colsample_bytree': 0.9539768842772781}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:26,021] Trial 138 finished with value: 0.4255389845911376 and parameters: {'num_leaves': 8, 'learning_rate': 0.038987363917371794, 'n_estimators': 424, 'subsample': 0.8274829714402641, 'colsample_bytree': 0.9688749020084532}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:29,905] Trial 139 finished with value: 0.43094541670362424 and parameters: {'num_leaves': 7, 'learning_rate': 0.02987821376111404, 'n_estimators': 458, 'subsample': 0.8713274305894115, 'colsample_bytree': 0.9793473889759066}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:33,900] Trial 140 finished with value: 0.42448866337192454 and parameters: {'num_leaves': 7, 'learning_rate': 0.052430119991928724, 'n_estimators': 471, 'subsample': 0.8526269829312451, 'colsample_bytree': 0.9103314386420416}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:37,136] Trial 141 finished with value: 0.0 and parameters: {'num_leaves': 6, 'learning_rate': 0.0006447068334791227, 'n_estimators': 445, 'subsample': 0.7257263583805275, 'colsample_bytree': 0.9587897746405933}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:40,432] Trial 142 finished with value: 0.4336617625819269 and parameters: {'num_leaves': 6, 'learning_rate': 0.050871867730790214, 'n_estimators': 483, 'subsample': 0.8085953022744237, 'colsample_bytree': 0.948069685887826}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:44,595] Trial 143 finished with value: 0.42787223615700076 and parameters: {'num_leaves': 7, 'learning_rate': 0.04124355435777904, 'n_estimators': 494, 'subsample': 0.5041178808920665, 'colsample_bytree': 0.9294110099929448}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:51,494] Trial 144 finished with value: 0.42411714146410767 and parameters: {'num_leaves': 12, 'learning_rate': 0.05714814455774836, 'n_estimators': 426, 'subsample': 0.8546448753948308, 'colsample_bytree': 0.9822594614758628}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:54,136] Trial 145 finished with value: 0.44297554058149513 and parameters: {'num_leaves': 6, 'learning_rate': 0.07018978796791428, 'n_estimators': 381, 'subsample': 0.7034023500843514, 'colsample_bytree': 0.9173226480594956}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:56,628] Trial 146 finished with value: 0.4335380418592398 and parameters: {'num_leaves': 6, 'learning_rate': 0.07284668730926608, 'n_estimators': 367, 'subsample': 0.8125070785513074, 'colsample_bytree': 0.9168653580805517}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:33:59,500] Trial 147 finished with value: 0.4367285931823236 and parameters: {'num_leaves': 6, 'learning_rate': 0.03394805578560312, 'n_estimators': 407, 'subsample': 0.8243468586603266, 'colsample_bytree': 0.9506794615341841}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:02,233] Trial 148 finished with value: 0.0 and parameters: {'num_leaves': 6, 'learning_rate': 0.00023862958857972635, 'n_estimators': 383, 'subsample': 0.8231722825362496, 'colsample_bytree': 0.9747668665388455}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:05,026] Trial 149 finished with value: 0.4365256197235465 and parameters: {'num_leaves': 6, 'learning_rate': 0.06777154302064486, 'n_estimators': 408, 'subsample': 0.835109344439697, 'colsample_bytree': 0.899854840846452}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:07,232] Trial 150 finished with value: 0.41038972593219525 and parameters: {'num_leaves': 5, 'learning_rate': 0.02209983601673053, 'n_estimators': 380, 'subsample': 0.7050625574059137, 'colsample_bytree': 0.9999126670590305}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:09,983] Trial 151 finished with value: 0.43241752281480333 and parameters: {'num_leaves': 6, 'learning_rate': 0.06849902823200484, 'n_estimators': 405, 'subsample': 0.7850085465126695, 'colsample_bytree': 0.9037008163167186}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:12,721] Trial 152 finished with value: 0.4335231863351227 and parameters: {'num_leaves': 6, 'learning_rate': 0.044489299271891845, 'n_estimators': 399, 'subsample': 0.7949472024440082, 'colsample_bytree': 0.9350524425032537}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:14,788] Trial 153 finished with value: 0.43089415253100816 and parameters: {'num_leaves': 5, 'learning_rate': 0.05705538385303668, 'n_estimators': 367, 'subsample': 0.8352935384276977, 'colsample_bytree': 0.9228873013019069}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:17,617] Trial 154 finished with value: 0.43209146059612974 and parameters: {'num_leaves': 6, 'learning_rate': 0.06493718857719706, 'n_estimators': 407, 'subsample': 0.8471354789813266, 'colsample_bytree': 0.9481207229582451}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:21,069] Trial 155 finished with value: 0.42969525260256153 and parameters: {'num_leaves': 7, 'learning_rate': 0.04855652089180917, 'n_estimators': 414, 'subsample': 0.8769388096247138, 'colsample_bytree': 0.8973000022727273}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:23,943] Trial 156 finished with value: 0.3123030685264931 and parameters: {'num_leaves': 6, 'learning_rate': 0.005573745438649169, 'n_estimators': 390, 'subsample': 0.8174111831778591, 'colsample_bytree': 0.9678822930864597}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:26,692] Trial 157 finished with value: 0.4059804232686006 and parameters: {'num_leaves': 6, 'learning_rate': 0.08358104158330208, 'n_estimators': 437, 'subsample': 0.8299668125952976, 'colsample_bytree': 0.16275839657702923}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:28,797] Trial 158 finished with value: 0.3580786209034386 and parameters: {'num_leaves': 5, 'learning_rate': 0.011391357440004808, 'n_estimators': 354, 'subsample': 0.7662471844752825, 'colsample_bytree': 0.9409054896708898}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:31,046] Trial 159 finished with value: 0.42438140615949127 and parameters: {'num_leaves': 5, 'learning_rate': 0.032274757234783104, 'n_estimators': 378, 'subsample': 0.694406582554409, 'colsample_bytree': 0.9199638401031864}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:35,789] Trial 160 finished with value: 0.42598540203473634 and parameters: {'num_leaves': 8, 'learning_rate': 0.09768699909758786, 'n_estimators': 467, 'subsample': 0.7294909311282332, 'colsample_bytree': 0.9635019742154325}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:39,691] Trial 161 finished with value: 0.4290275988166433 and parameters: {'num_leaves': 7, 'learning_rate': 0.03659065204600287, 'n_estimators': 450, 'subsample': 0.8597788512938931, 'colsample_bytree': 0.9512299020004196}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:43,458] Trial 162 finished with value: 0.4324507080575719 and parameters: {'num_leaves': 7, 'learning_rate': 0.04372380614045015, 'n_estimators': 435, 'subsample': 0.8648887967425721, 'colsample_bytree': 0.9801283851114646}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:46,344] Trial 163 finished with value: 0.43897706197190073 and parameters: {'num_leaves': 6, 'learning_rate': 0.06883854249423879, 'n_estimators': 416, 'subsample': 0.8864701575088031, 'colsample_bytree': 0.9034084199184861}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:49,089] Trial 164 finished with value: 0.43208561349094615 and parameters: {'num_leaves': 6, 'learning_rate': 0.07052535309767095, 'n_estimators': 396, 'subsample': 0.8871638187648139, 'colsample_bytree': 0.9060276792863446}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:34:57,733] Trial 165 finished with value: 0.4229355987778116 and parameters: {'num_leaves': 18, 'learning_rate': 0.05532549833054208, 'n_estimators': 385, 'subsample': 0.7120274667346911, 'colsample_bytree': 0.9278186577739768}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:00,557] Trial 166 finished with value: 0.4321480048743164 and parameters: {'num_leaves': 6, 'learning_rate': 0.06471017097533321, 'n_estimators': 415, 'subsample': 0.746118468776016, 'colsample_bytree': 0.8903112352392685}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:03,431] Trial 167 finished with value: 0.4336544823524912 and parameters: {'num_leaves': 6, 'learning_rate': 0.08079791297791576, 'n_estimators': 426, 'subsample': 0.778328445276145, 'colsample_bytree': 0.9436813788125263}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:06,224] Trial 168 finished with value: 0.4348745551270093 and parameters: {'num_leaves': 5, 'learning_rate': 0.09873048107215343, 'n_estimators': 497, 'subsample': 0.8022170293248216, 'colsample_bytree': 0.9826407887343717}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:08,351] Trial 169 finished with value: 0.43777670793953616 and parameters: {'num_leaves': 5, 'learning_rate': 0.05181781783363102, 'n_estimators': 372, 'subsample': 0.7612268094844492, 'colsample_bytree': 0.9011781862108293}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:10,150] Trial 170 finished with value: 0.41828217476872975 and parameters: {'num_leaves': 4, 'learning_rate': 0.05122339225698746, 'n_estimators': 372, 'subsample': 0.7612728343061369, 'colsample_bytree': 0.9652839859630651}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:12,326] Trial 171 finished with value: 0.43397058188843207 and parameters: {'num_leaves': 5, 'learning_rate': 0.06710157082854276, 'n_estimators': 385, 'subsample': 0.7381861303140347, 'colsample_bytree': 0.916504299114375}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:14,895] Trial 172 finished with value: 0.4402002009720388 and parameters: {'num_leaves': 6, 'learning_rate': 0.054518705978845394, 'n_estimators': 364, 'subsample': 0.7261251295938161, 'colsample_bytree': 0.8981155178770881}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:17,015] Trial 173 finished with value: 0.42638922336622676 and parameters: {'num_leaves': 5, 'learning_rate': 0.04515437491717442, 'n_estimators': 359, 'subsample': 0.7287506995596763, 'colsample_bytree': 0.9347244992829721}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:19,609] Trial 174 finished with value: 0.43696874497777244 and parameters: {'num_leaves': 6, 'learning_rate': 0.05557819237319477, 'n_estimators': 369, 'subsample': 0.7196139332632525, 'colsample_bytree': 0.8705080129950404}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:21,705] Trial 175 finished with value: 0.43182416397262696 and parameters: {'num_leaves': 5, 'learning_rate': 0.055512626624125205, 'n_estimators': 368, 'subsample': 0.7044476507603662, 'colsample_bytree': 0.8693891053598377}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:24,105] Trial 176 finished with value: 0.44181569911984864 and parameters: {'num_leaves': 6, 'learning_rate': 0.08098296452725962, 'n_estimators': 352, 'subsample': 0.7227448675083291, 'colsample_bytree': 0.8950544975741498}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:26,654] Trial 177 finished with value: 0.4398162003415983 and parameters: {'num_leaves': 6, 'learning_rate': 0.08255230151215599, 'n_estimators': 359, 'subsample': 0.7227470503595631, 'colsample_bytree': 0.847139286597204}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:29,116] Trial 178 finished with value: 0.43608813413653963 and parameters: {'num_leaves': 6, 'learning_rate': 0.0796631046846492, 'n_estimators': 352, 'subsample': 0.7186464883307315, 'colsample_bytree': 0.8554722979581996}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:30,770] Trial 179 finished with value: 0.4320737511175203 and parameters: {'num_leaves': 4, 'learning_rate': 0.09945542079020941, 'n_estimators': 356, 'subsample': 0.7460303062823751, 'colsample_bytree': 0.8846209882070467}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:32,812] Trial 180 finished with value: 0.43130768965481386 and parameters: {'num_leaves': 5, 'learning_rate': 0.08313275249112898, 'n_estimators': 365, 'subsample': 0.7233615091537198, 'colsample_bytree': 0.8382309082377811}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:35,494] Trial 181 finished with value: 0.4368402874196695 and parameters: {'num_leaves': 6, 'learning_rate': 0.0613321898791604, 'n_estimators': 377, 'subsample': 0.7318033754495655, 'colsample_bytree': 0.8641870017534129}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:38,130] Trial 182 finished with value: 0.4376531799411838 and parameters: {'num_leaves': 6, 'learning_rate': 0.07176837814985247, 'n_estimators': 383, 'subsample': 0.7365815738080133, 'colsample_bytree': 0.857991690433474}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:40,719] Trial 183 finished with value: 0.43368738597125683 and parameters: {'num_leaves': 6, 'learning_rate': 0.06672475672539818, 'n_estimators': 370, 'subsample': 0.7108104370609778, 'colsample_bytree': 0.8853438662580981}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:42,767] Trial 184 finished with value: 0.4343855863565905 and parameters: {'num_leaves': 5, 'learning_rate': 0.0796111409493918, 'n_estimators': 360, 'subsample': 0.7388758562288362, 'colsample_bytree': 0.8249500051510242}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:44,972] Trial 185 finished with value: 0.4386123826592637 and parameters: {'num_leaves': 5, 'learning_rate': 0.07804014390987737, 'n_estimators': 381, 'subsample': 0.7604967152152424, 'colsample_bytree': 0.9053083390791974}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:47,136] Trial 186 finished with value: 0.4362937920287937 and parameters: {'num_leaves': 5, 'learning_rate': 0.07864500815436719, 'n_estimators': 382, 'subsample': 0.7577166357314813, 'colsample_bytree': 0.9089685567321854}. Best is trial 124 with value: 0.44349071952527447.\n",
      "[I 2024-10-31 14:35:49,418] Trial 187 finished with value: 0.44603793808703324 and parameters: {'num_leaves': 5, 'learning_rate': 0.08604312752770567, 'n_estimators': 393, 'subsample': 0.7484054808320165, 'colsample_bytree': 0.9002924035826438}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:35:51,783] Trial 188 finished with value: 0.43517161971705975 and parameters: {'num_leaves': 5, 'learning_rate': 0.07044300797626762, 'n_estimators': 392, 'subsample': 0.7720208362256934, 'colsample_bytree': 0.8966288260474834}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:35:54,958] Trial 189 finished with value: 0.43143181960224297 and parameters: {'num_leaves': 6, 'learning_rate': 0.09732774942764866, 'n_estimators': 382, 'subsample': 0.6980636719387295, 'colsample_bytree': 0.8522088537407996}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:35:56,982] Trial 190 finished with value: 0.4258281160705032 and parameters: {'num_leaves': 4, 'learning_rate': 0.07091337010389452, 'n_estimators': 395, 'subsample': 0.7413589619756525, 'colsample_bytree': 0.9062685101686477}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:35:59,308] Trial 191 finished with value: 0.4401882709221486 and parameters: {'num_leaves': 5, 'learning_rate': 0.08539032363268068, 'n_estimators': 378, 'subsample': 0.7569976139940497, 'colsample_bytree': 0.923653692754185}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:36:01,617] Trial 192 finished with value: 0.4350118004027067 and parameters: {'num_leaves': 5, 'learning_rate': 0.061111429574529225, 'n_estimators': 376, 'subsample': 0.7561977971436974, 'colsample_bytree': 0.9229618704119952}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:36:04,126] Trial 193 finished with value: 0.4351199589494496 and parameters: {'num_leaves': 6, 'learning_rate': 0.0841654569741499, 'n_estimators': 351, 'subsample': 0.7318166343781403, 'colsample_bytree': 0.881406609520959}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:36:06,923] Trial 194 finished with value: 0.4336027977329347 and parameters: {'num_leaves': 6, 'learning_rate': 0.09892857002986329, 'n_estimators': 385, 'subsample': 0.7628034341427496, 'colsample_bytree': 0.8917718963043934}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:36:09,100] Trial 195 finished with value: 0.43266356228951314 and parameters: {'num_leaves': 5, 'learning_rate': 0.048008575578790624, 'n_estimators': 363, 'subsample': 0.7460754452253856, 'colsample_bytree': 0.9251476530205085}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:36:10,991] Trial 196 finished with value: 0.4285143552014635 and parameters: {'num_leaves': 4, 'learning_rate': 0.07601137021717283, 'n_estimators': 376, 'subsample': 0.7224723342424999, 'colsample_bytree': 0.9090937721058558}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:36:18,377] Trial 197 finished with value: 0.4144066906200147 and parameters: {'num_leaves': 15, 'learning_rate': 0.06418085825208826, 'n_estimators': 389, 'subsample': 0.7335851491819583, 'colsample_bytree': 0.856194454802386}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:36:20,413] Trial 198 finished with value: 0.004046093483780201 and parameters: {'num_leaves': 5, 'learning_rate': 0.002271613950431558, 'n_estimators': 372, 'subsample': 0.7797070849450808, 'colsample_bytree': 0.402280369564997}. Best is trial 187 with value: 0.44603793808703324.\n",
      "[I 2024-10-31 14:36:22,956] Trial 199 finished with value: 0.43470475660620655 and parameters: {'num_leaves': 6, 'learning_rate': 0.053141724380699265, 'n_estimators': 362, 'subsample': 0.6840879225312226, 'colsample_bytree': 0.9337952170013246}. Best is trial 187 with value: 0.44603793808703324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial parameters: {'num_leaves': 5, 'learning_rate': 0.08604312752770567, 'n_estimators': 393, 'subsample': 0.7484054808320165, 'colsample_bytree': 0.9002924035826438}\n",
      "Best Matthews Correlation Coefficient: 0.44603793808703324\n",
      "train score 0.9876148148148148 \n",
      " test score 0.8798222222222222\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('num_leaves', 3, 20),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    cla = XGBClassifier(**params)\n",
    "\n",
    "    f1score = cross_val_score(cla, train, target, cv=5, scoring='f1').mean()\n",
    "\n",
    "    return f1score\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "print(\"Best trial parameters:\", study.best_trial.params)\n",
    "print(\"Best Matthews Correlation Coefficient:\", study.best_value)\n",
    "\n",
    "# Retrieve the best parameters from the Optuna study\n",
    "best_params = study.best_params\n",
    "\n",
    "cla_xgb = XGBClassifier(**best_params)\n",
    "cla_xgb.fit(x_train, y_train)\n",
    "\n",
    "train_score = cla_xgb.score(x_train, y_train)\n",
    "test_score = cla_xgb.score(x_test, y_test)\n",
    "\n",
    "joblib.dump(cla_xgb, 'xgb_model.pkl')\n",
    "\n",
    "print(f'train score {train_score} \\n test score {test_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.44652984  1.4470523   1.23559448 ...  1.17896272  0.20494495\n",
      "   0.37753828]\n",
      " [-1.19146359 -1.05887489  1.23559448 ... -0.76938659 -0.08610436\n",
      "  -1.26137274]\n",
      " [ 0.2984039  -0.78043854 -0.29994133 ...  0.51809907  1.07809289\n",
      "  -1.1310847 ]\n",
      " ...\n",
      " [ 0.7950264   0.33330688  1.23559448 ...  0.04042819 -1.24410906\n",
      "  -0.13646677]\n",
      " [-0.77761151  1.4470523  -0.29994133 ...  0.38455667  1.16478843\n",
      "   0.02551454]\n",
      " [ 0.46394474 -1.05887489 -1.83547713 ...  1.43577502  0.30402557\n",
      "  -0.33887017]]\n"
     ]
    }
   ],
   "source": [
    "test_data=pd.read_csv(\"test.csv\",index_col='id')\n",
    "id_list=test_data.index.tolist()\n",
    "categorical_feature = list(test_data.select_dtypes(include='object').columns)\n",
    "test_data[categorical_feature] =ordinal_encoder.fit_transform(test_data[categorical_feature])\n",
    "test_data=scaler.fit_transform(test_data)\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model_lgbm = joblib.load('lgbm_model.pkl')\n",
    "y_pred_lgbm_proba = loaded_model_lgbm.predict_proba(test_data)\n",
    "y_pred_lgbm = loaded_model_lgbm.predict(test_data)\n",
    "\n",
    "loaded_model_xgb = joblib.load('xgb_model.pkl')\n",
    "y_pred_xgb_proba = loaded_model_xgb.predict_proba(test_data)\n",
    "y_pred_xgb = loaded_model_xgb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done submission_lgbm.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"./submission/submission_lgbm.csv\",\"w+\",encoding=\"utf-8\",newline=\"\") as f:\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerow([\"id\",\"subscribe\"])\n",
    "    for i in range(0,len(id_list)):\n",
    "        writer.writerow([id_list[i],\"yes\" if(y_pred_lgbm[i]) else \"no\"])\n",
    "\n",
    "print(\"Done submission_lgbm.csv\")\n",
    "\n",
    "with open(\"./submission/submission_xgb.csv\",\"w+\",encoding=\"utf-8\",newline=\"\") as f:\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerow([\"id\",\"subscribe\"])\n",
    "    for i in range(0,len(id_list)):\n",
    "        writer.writerow([id_list[i],\"yes\" if(y_pred_xgb[i]) else \"no\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
